{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporal Fusion Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import model and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import copy\n",
    "from pathlib import Path\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.callbacks import EarlyStopping, LearningRateMonitor, ModelCheckpoint\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from pytorch_forecasting import Baseline, TemporalFusionTransformer, TimeSeriesDataSet\n",
    "from pytorch_forecasting.data import GroupNormalizer, MultiNormalizer\n",
    "from pytorch_forecasting.metrics import MAE, SMAPE, PoissonLoss, QuantileLoss\n",
    "from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters\n",
    "import multiprocessing\n",
    "import torch\n",
    "from pytorch_forecasting.metrics import RMSE, MAE\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(r\"D:\\Study\\Research-Lee 2024\\Unilever\\Unilever Data\\Unprocessed panda\\DEODORANT & FRAGRANCE_dataset.npz\")\n",
    "\n",
    "X = data['array_3d']  # Shape: (timestep, prediction_window, node, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180, 6884, 233)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape and convert data to pandas DataFrame\n",
    "def to_dataframe(X, time_col='time_idx', node_col='node_id'):\n",
    "    time_steps, nodes, features = X.shape\n",
    "    data_list = []\n",
    "\n",
    "    for t in range(time_steps):\n",
    "        for n in range(nodes):\n",
    "            row = {\n",
    "                time_col: t,\n",
    "                node_col: n,\n",
    "                **{f'feature_{i}': X[t, n, i] for i in range(features)},\n",
    "            }\n",
    "            data_list.append(row)\n",
    "\n",
    "    return pd.DataFrame(data_list)\n",
    "\n",
    "df = to_dataframe(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_idx</th>\n",
       "      <th>node_id</th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_223</th>\n",
       "      <th>feature_224</th>\n",
       "      <th>feature_225</th>\n",
       "      <th>feature_226</th>\n",
       "      <th>feature_227</th>\n",
       "      <th>feature_228</th>\n",
       "      <th>feature_229</th>\n",
       "      <th>feature_230</th>\n",
       "      <th>feature_231</th>\n",
       "      <th>feature_232</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239115</th>\n",
       "      <td>179</td>\n",
       "      <td>6879</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239116</th>\n",
       "      <td>179</td>\n",
       "      <td>6880</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239117</th>\n",
       "      <td>179</td>\n",
       "      <td>6881</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239118</th>\n",
       "      <td>179</td>\n",
       "      <td>6882</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239119</th>\n",
       "      <td>179</td>\n",
       "      <td>6883</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1239120 rows × 235 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         time_idx  node_id  feature_0  feature_1  feature_2  feature_3  \\\n",
       "0               0        0        0.0        0.0        0.0        0.0   \n",
       "1               0        1        0.0        0.0        0.0        0.0   \n",
       "2               0        2        0.0        0.0        0.0        0.0   \n",
       "3               0        3        0.0        0.0        0.0        0.0   \n",
       "4               0        4        0.0        0.0        0.0        0.0   \n",
       "...           ...      ...        ...        ...        ...        ...   \n",
       "1239115       179     6879        0.0        0.0        0.0        1.0   \n",
       "1239116       179     6880        0.0        0.0        0.0        0.0   \n",
       "1239117       179     6881        0.0        0.0        0.0        1.0   \n",
       "1239118       179     6882        0.0        0.0        0.0        0.0   \n",
       "1239119       179     6883        0.0        0.0        0.0        0.0   \n",
       "\n",
       "         feature_4  feature_5  feature_6  feature_7  ...  feature_223  \\\n",
       "0              0.0        0.0       0.00        0.0  ...          0.0   \n",
       "1              0.0        0.0       0.00        0.0  ...          0.0   \n",
       "2              0.0        0.0       0.00        0.0  ...          0.0   \n",
       "3              0.0        0.0       0.00        0.0  ...          0.0   \n",
       "4              0.0        0.0       0.00        0.0  ...          0.0   \n",
       "...            ...        ...        ...        ...  ...          ...   \n",
       "1239115        0.0        0.0       1.98        0.0  ...          0.0   \n",
       "1239116        0.0        0.0       0.00        0.0  ...          0.0   \n",
       "1239117        0.0        0.0      17.50        0.0  ...          0.0   \n",
       "1239118        0.0        0.0       0.00        0.0  ...          0.0   \n",
       "1239119        0.0        0.0       0.00        0.0  ...          0.0   \n",
       "\n",
       "         feature_224  feature_225  feature_226  feature_227  feature_228  \\\n",
       "0                0.0          0.0          0.0          0.0          0.0   \n",
       "1                0.0          0.0          0.0          0.0          0.0   \n",
       "2                0.0          0.0          0.0          0.0          0.0   \n",
       "3                0.0          0.0          0.0          0.0          0.0   \n",
       "4                0.0          0.0          0.0          0.0          0.0   \n",
       "...              ...          ...          ...          ...          ...   \n",
       "1239115          0.0          1.0          0.0          0.0          0.0   \n",
       "1239116          0.0          0.0          0.0          0.0          0.0   \n",
       "1239117          0.0          1.0          0.0          0.0          0.0   \n",
       "1239118          0.0          0.0          0.0          0.0          0.0   \n",
       "1239119          0.0          0.0          0.0          0.0          0.0   \n",
       "\n",
       "         feature_229  feature_230  feature_231  feature_232  \n",
       "0                0.0          0.0          0.0          0.0  \n",
       "1                0.0          0.0          0.0          0.0  \n",
       "2                0.0          0.0          0.0          0.0  \n",
       "3                0.0          0.0          0.0          0.0  \n",
       "4                0.0          0.0          0.0          0.0  \n",
       "...              ...          ...          ...          ...  \n",
       "1239115          0.0          0.0          0.0          0.0  \n",
       "1239116          0.0          0.0          0.0          0.0  \n",
       "1239117          0.0          0.0          0.0          0.0  \n",
       "1239118          0.0          0.0          0.0          0.0  \n",
       "1239119          0.0          0.0          0.0          0.0  \n",
       "\n",
       "[1239120 rows x 235 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train, validation, and test sets\n",
    "def split_data(df, time_col, test_size=0.15, val_size=0.15):\n",
    "    # Split the DataFrame into training and temporary sets\n",
    "    train_df, temp_df = train_test_split(df, test_size=test_size + val_size, shuffle=False, stratify=None)\n",
    "    # Split the temporary set into validation and test sets\n",
    "    val_df, test_df = train_test_split(temp_df, test_size=test_size / (test_size + val_size), shuffle=False, stratify=None)\n",
    "    return train_df, val_df, test_df\n",
    "\n",
    "train_df, val_df, test_df = split_data(df, time_col='time_idx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(867384, 235)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(185868, 235)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(185868, 235)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for missing values...\n",
      "feature_19     34027\n",
      "feature_20     34027\n",
      "feature_21     34027\n",
      "feature_22     34027\n",
      "feature_23     34027\n",
      "               ...  \n",
      "feature_222    34027\n",
      "feature_226    34027\n",
      "feature_227    34027\n",
      "feature_229    34027\n",
      "feature_232    34027\n",
      "Length: 112, dtype: int64\n",
      "Checking for missing values...\n",
      "feature_19     14107\n",
      "feature_20     14107\n",
      "feature_21     14107\n",
      "feature_22     14107\n",
      "feature_23     14107\n",
      "               ...  \n",
      "feature_222    14107\n",
      "feature_226    14107\n",
      "feature_227    14107\n",
      "feature_229    14107\n",
      "feature_232    14107\n",
      "Length: 112, dtype: int64\n",
      "Checking for missing values...\n",
      "feature_19     16115\n",
      "feature_20     16115\n",
      "feature_21     16115\n",
      "feature_22     16115\n",
      "feature_23     16115\n",
      "               ...  \n",
      "feature_222    16115\n",
      "feature_226    16115\n",
      "feature_227    16115\n",
      "feature_229    16115\n",
      "feature_232    16115\n",
      "Length: 112, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Define categorical and continuous features\n",
    "categorical_features = ['node_id']\n",
    "continuous_features = [f'feature_{i}' for i in range(1, X.shape[-1])]\n",
    "\n",
    "def create_dataset(df, time_col, target_col, group_col, max_encoder_length, max_prediction_length):\n",
    "    # Convert the group column to string type\n",
    "    df[group_col] = df[group_col].astype(str)\n",
    "    \n",
    "    # Check for missing values\n",
    "    print(\"Checking for missing values...\")\n",
    "    missing_summary = df.isna().sum()\n",
    "    print(missing_summary[missing_summary > 0])\n",
    "\n",
    "    # Handle missing values\n",
    "    # Drop rows with missing target values\n",
    "    df = df.dropna(subset=[target_col])\n",
    "    \n",
    "    # Fill missing values for features using mean imputation\n",
    "    feature_cols = [col for col in df.columns if col.startswith('feature_') and col != \"feature_0\"]\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    df[feature_cols] = imputer.fit_transform(df[feature_cols])\n",
    "    \n",
    "    # Define categorical and continuous features\n",
    "    static_categoricals = [group_col]\n",
    "    time_varying_known_reals = feature_cols\n",
    "    time_varying_unknown_reals = [target_col]\n",
    "    \n",
    "    return TimeSeriesDataSet(\n",
    "        df,\n",
    "        time_idx=time_col,\n",
    "        target=target_col,\n",
    "        group_ids=[group_col],\n",
    "        min_encoder_length=max_encoder_length,\n",
    "        max_encoder_length=max_encoder_length,\n",
    "        min_prediction_length=max_prediction_length,\n",
    "        max_prediction_length=max_prediction_length,\n",
    "        static_categoricals=static_categoricals,\n",
    "        static_reals=[],  # No static real features in this example\n",
    "        time_varying_known_categoricals=[],\n",
    "        time_varying_known_reals=time_varying_known_reals,\n",
    "        time_varying_unknown_categoricals=[],\n",
    "        time_varying_unknown_reals=time_varying_unknown_reals,\n",
    "        allow_missing_timesteps=True\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "# Set maximum lengths\n",
    "max_encoder_length = 6  # Length of the historical data\n",
    "max_prediction_length = 6  # Length of the forecast\n",
    "\n",
    "train_dataset = create_dataset(train_df, time_col='time_idx', target_col='feature_0', group_col='node_id', max_encoder_length=max_encoder_length, max_prediction_length=max_prediction_length)\n",
    "val_dataset = create_dataset(val_df, time_col='time_idx', target_col='feature_0', group_col='node_id', max_encoder_length=max_encoder_length, max_prediction_length=max_prediction_length)\n",
    "test_dataset = create_dataset(test_df, time_col='time_idx', target_col='feature_0', group_col='node_id', max_encoder_length=max_encoder_length, max_prediction_length=max_prediction_length)\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 128\n",
    "train_dataloader = train_dataset.to_dataloader(train=True, batch_size=batch_size, num_workers=4)\n",
    "val_dataloader = val_dataset.to_dataloader(train=False, batch_size=batch_size, num_workers=4)\n",
    "test_dataloader = test_dataset.to_dataloader(train=False, batch_size=batch_size, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available. Using GPU.\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "    print(\"GPU is available. Using GPU.\")\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    print(\"GPU not available. Using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set float32 matrix multiplication precision\n",
    "torch.set_float32_matmul_precision('medium')  # or 'high'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
      "c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:208: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in network: 479.6k\n"
     ]
    }
   ],
   "source": [
    "pl.seed_everything(42)\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=10,\n",
    "    accelerator=\"cuda\",\n",
    "    # clipping gradients is a hyperparameter and important to prevent divergence\n",
    "    # of the gradient for recurrent neural networks\n",
    "    gradient_clip_val=0.2,\n",
    "    log_every_n_steps=10\n",
    ")\n",
    "\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    train_dataset,\n",
    "    # not meaningful for finding the learning rate but otherwise very important\n",
    "    learning_rate=0.008,\n",
    "    hidden_size=12,  # most important hyperparameter apart from learning rate\n",
    "    # number of attention heads. Set to up to 4 for large datasets\n",
    "    attention_head_size=4,\n",
    "    dropout=0.1,  # between 0.1 and 0.3 are good values\n",
    "    hidden_continuous_size=12,  # set to <= hidden_size\n",
    "    loss=QuantileLoss(),\n",
    "    optimizer=\"Ranger\"\n",
    "    # reduce learning rate if no improvement in validation loss after x epochs\n",
    "    # reduce_on_plateau_patience=1000,\n",
    ").to(device)\n",
    "\n",
    "print(f\"Number of parameters in network: {tft.size() / 1e3:.1f}k\")\n",
    "\n",
    "class TFTLightningModule(pl.LightningModule):\n",
    "    def __init__(self, tft):\n",
    "        super().__init__()\n",
    "        self.tft = tft\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.tft(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "\n",
    "        # Extract prediction from tuple if necessary\n",
    "        if isinstance(y_hat, tuple):\n",
    "            y_hat = y_hat[0]\n",
    "\n",
    "        loss = self.tft.loss(y_hat, y)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "\n",
    "        # Ensure y_hat and y are tensors and not tuples, and have the correct shape\n",
    "        if isinstance(y_hat, tuple):\n",
    "            y_hat = y_hat[0]  # Assuming the first element of the tuple is the prediction\n",
    "        if isinstance(y, tuple):\n",
    "            y = y[0]  # Assuming the first element of the tuple is the target\n",
    "\n",
    "        loss = self.tft.loss(y_hat, y)\n",
    "        self.log(\"val_loss\", loss)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return self.tft.configure_optimizers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:419: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n",
      "c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:419: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b26b772a43824f988a527ac2ffe4d41d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100` reached.\n",
      "Learning rate set to 0.008317637711026716\n",
      "Restoring states from the checkpoint path at d:\\Study\\Research-Lee 2024\\Unilever\\Transformer\\.lr_find_bc08e6ee-3fab-4438-9ed6-8937a560a9e5.ckpt\n",
      "Restored all states from the checkpoint at d:\\Study\\Research-Lee 2024\\Unilever\\Transformer\\.lr_find_bc08e6ee-3fab-4438-9ed6-8937a560a9e5.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "suggested learning rate: 0.008317637711026716\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_26968\\4268711780.py:14: UserWarning: Matplotlib is currently using module://matplotlib_inline.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  fig.show()\n"
     ]
    }
   ],
   "source": [
    "# find optimal learning rate\n",
    "from lightning.pytorch.tuner import Tuner\n",
    "\n",
    "res = Tuner(trainer).lr_find(\n",
    "    tft,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    "    max_lr=10.0,\n",
    "    min_lr=1e-6,\n",
    ")\n",
    "\n",
    "print(f\"suggested learning rate: {res.suggestion()}\")\n",
    "fig = res.plot(show=True, suggest=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type                      | Params | Mode \n",
      "-----------------------------------------------------------\n",
      "0 | tft  | TemporalFusionTransformer | 479 K  | train\n",
      "-----------------------------------------------------------\n",
      "479 K     Trainable params\n",
      "0         Non-trainable params\n",
      "479 K     Total params\n",
      "1.918     Total estimated model params size (MB)\n",
      "5035      Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cafc35520e9e4c8397fd84e511979e2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lightning\\pytorch\\utilities\\data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 128. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b3c9bc510fa4882b9a4150342c1499b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "beb6ae2120cc42f58c6a3a01595da27b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lightning\\pytorch\\utilities\\data.py:78: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 64. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d6e3fb1e48b480b9210f9ec18ee9dc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c78eb6e2b7024e03a4546e4d238c3969",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0455d543fe3240e5be492a51a6183e15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d54d3f14d85f498fab5b27f2de7401f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a03380fa1dd40bdab3930c499bcf67d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "458df4b3d77b46ba905e01100bdfc1e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc8381203cde4e26bab3dbc70edcc088",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cca32eee17234816adeb2df8fa010757",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "201951f4acc245d4a9a316d5812e4bf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    }
   ],
   "source": [
    "# Create the LightningModule wrapper\n",
    "tft_lightning = TFTLightningModule(tft)\n",
    "\n",
    "# # Fit the LightningModule wrapper\n",
    "trainer.fit(\n",
    "    tft_lightning,  # Pass the LightningModule wrapper\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    ")\n",
    "\n",
    "model_save_path = \"trained_unilever_tft_model.pth\"\n",
    "torch.save(tft.state_dict(), model_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters\n",
    "#\n",
    "# # Create study\n",
    "# study = optimize_hyperparameters(\n",
    "#     train_dataloader,\n",
    "#     val_dataloader,\n",
    "#     model_path=\"optuna_test\",\n",
    "#     n_trials=5,\n",
    "#     max_epochs=10,\n",
    "#     gradient_clip_val_range=(0.01, 1.0),\n",
    "#     hidden_size_range=(8, 128),\n",
    "#     hidden_continuous_size_range=(8, 128),\n",
    "#     attention_head_size_range=(1, 4),\n",
    "#     learning_rate_range=(0.001, 0.1),\n",
    "#     dropout_range=(0.1, 0.3),\n",
    "#     trainer_kwargs=dict(limit_train_batches=100),\n",
    "#     reduce_on_plateau_patience=4,\n",
    "#     use_learning_rate_finder=False,  # use Optuna to find ideal learning rate or use in-built learning rate finder\n",
    "# )\n",
    "#\n",
    "# # Save study results - we can resume tuning at a later point in time\n",
    "# with open(\"test_study.pkl\", \"wb\") as fout:\n",
    "#     pickle.dump(study, fout)\n",
    "#\n",
    "# # Show best hyperparameters\n",
    "# print(\"Best hyperparameters:\", study.best_trial.params)\n",
    "#\n",
    "# # Initialize the model with best hyperparameters\n",
    "# best_trial = study.best_trial\n",
    "# best_hparams = best_trial.params\n",
    "#\n",
    "# best_tft = TemporalFusionTransformer.from_dataset(\n",
    "#     training,\n",
    "#     hidden_size=best_hparams['hidden_size'],\n",
    "#     dropout=best_hparams['dropout'],\n",
    "#     hidden_continuous_size=int(best_hparams['hidden_continuous_size']),\n",
    "#     attention_head_size=int(best_hparams['attention_head_size']),\n",
    "#     learning_rate=best_hparams['learning_rate'],\n",
    "#     loss=QuantileLoss(),\n",
    "#     log_interval=10,  # Log every 10 batches\n",
    "#     optimizer=\"Ranger\",\n",
    "#     reduce_on_plateau_patience=4,\n",
    "# ).to(device)  # Move the model to GPU\n",
    "#\n",
    "# # Train with best hyperparameters\n",
    "# trainer.fit(\n",
    "#     TFTLightningModule(best_tft),  # Pass the LightningModule wrapper\n",
    "#     train_dataloaders=train_dataloader,\n",
    "#     val_dataloaders=val_dataloader,\n",
    "# )\n",
    "\n",
    "# model_save_path = \"trained_best_tft_model.pth\"\n",
    "# # torch.save(tft.state_dict(), model_save_path)\n",
    "# tft.load_state_dict(torch.load(model_save_path, map_location=device))\n",
    "# calcualte mean absolute error on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'collections.OrderedDict' object has no attribute 'state_dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m model_save_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrained_best_tft_model.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(\u001b[43mtft\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m(), model_save_path)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# tft.load_state_dict(torch.load(model_save_path, map_location=device))\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'collections.OrderedDict' object has no attribute 'state_dict'"
     ]
    }
   ],
   "source": [
    "model_save_path = \"trained_best_tft_model.pth\"\n",
    "torch.save(tft.state_dict(), model_save_path)\n",
    "# tft.load_state_dict(torch.load(model_save_path, map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_8628\\452137744.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  tft.load_state_dict(torch.load(model_save_path, map_location=device))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_save_path = \"trained_best_tft_model.pth\"\n",
    "tft.load_state_dict(torch.load(model_save_path, map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:419: Consider setting `persistent_workers=True` in 'predict_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    }
   ],
   "source": [
    "# predictions = tft.predict(val_dataloader, return_y=True, trainer_kwargs=dict(accelerator=\"cuda\"))\n",
    "# print(f\"RMSE{RMSE()(predictions.output, predictions.y)}\")\n",
    "# print(\"y = True\")\n",
    "# print(f\"y: {predictions.y}\")\n",
    "# print(f\"output: {predictions.output}\")\n",
    "\n",
    "# Make predictions on validation data\n",
    "val_predictions = tft.predict(val_dataloader, trainer_kwargs=dict(accelerator=\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([110144, 6])\n"
     ]
    }
   ],
   "source": [
    "print(val_predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([185868, 233])\n"
     ]
    }
   ],
   "source": [
    "actual_val_targets = val_dataloader.dataset.data[\"reals\"]\n",
    "print(actual_val_targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:419: Consider setting `persistent_workers=True` in 'predict_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    }
   ],
   "source": [
    "# Predictions on test data\n",
    "test_predictions = tft.predict(test_dataloader, return_index=True, mode=\"raw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([110144, 6, 7])\n"
     ]
    }
   ],
   "source": [
    "print(test_predictions.output.prediction.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output(prediction=tensor([[[-9.0158e-01, -5.4173e-02, -4.2212e-01,  ..., -1.7432e+00,\n",
      "           8.6339e-01,  2.1130e+00],\n",
      "         [-9.0211e-01, -4.5826e-02, -4.2133e-01,  ..., -1.7416e+00,\n",
      "           8.8338e-01,  2.2247e+00],\n",
      "         [-9.0161e-01, -4.5502e-02, -4.2029e-01,  ..., -1.7403e+00,\n",
      "           8.8562e-01,  2.2272e+00],\n",
      "         [-9.0101e-01, -4.5231e-02, -4.1940e-01,  ..., -1.7398e+00,\n",
      "           8.8669e-01,  2.2274e+00],\n",
      "         [-9.0034e-01, -4.4788e-02, -4.1843e-01,  ..., -1.7393e+00,\n",
      "           8.8764e-01,  2.2273e+00],\n",
      "         [-9.0022e-01, -4.6509e-02, -4.1976e-01,  ..., -1.7450e+00,\n",
      "           8.8544e-01,  2.2281e+00]],\n",
      "\n",
      "        [[-8.9901e-01, -5.2433e-02, -4.1897e-01,  ..., -1.7425e+00,\n",
      "           8.6514e-01,  2.1126e+00],\n",
      "         [-8.9800e-01, -4.3205e-02, -4.1613e-01,  ..., -1.7405e+00,\n",
      "           8.8760e-01,  2.2269e+00],\n",
      "         [-8.9734e-01, -4.2931e-02, -4.1495e-01,  ..., -1.7393e+00,\n",
      "           8.8995e-01,  2.2294e+00],\n",
      "         [-8.9656e-01, -4.2488e-02, -4.1372e-01,  ..., -1.7384e+00,\n",
      "           8.9164e-01,  2.2303e+00],\n",
      "         [-8.9634e-01, -4.4182e-02, -4.1491e-01,  ..., -1.7440e+00,\n",
      "           8.8982e-01,  2.2315e+00],\n",
      "         [-8.9507e-01, -4.1695e-02, -4.1180e-01,  ..., -1.7380e+00,\n",
      "           8.9306e-01,  2.2292e+00]],\n",
      "\n",
      "        [[-8.9979e-01, -5.2944e-02, -4.1995e-01,  ..., -1.7426e+00,\n",
      "           8.6417e-01,  2.1114e+00],\n",
      "         [-8.9823e-01, -4.3419e-02, -4.1648e-01,  ..., -1.7407e+00,\n",
      "           8.8713e-01,  2.2263e+00],\n",
      "         [-8.9753e-01, -4.2988e-02, -4.1514e-01,  ..., -1.7392e+00,\n",
      "           8.8986e-01,  2.2294e+00],\n",
      "         [-8.9732e-01, -4.4704e-02, -4.1618e-01,  ..., -1.7444e+00,\n",
      "           8.8864e-01,  2.2316e+00],\n",
      "         [-8.9599e-01, -4.2255e-02, -4.1304e-01,  ..., -1.7383e+00,\n",
      "           8.9215e-01,  2.2296e+00],\n",
      "         [-8.9522e-01, -4.1698e-02, -4.1192e-01,  ..., -1.7377e+00,\n",
      "           8.9306e-01,  2.2293e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-8.3828e-01, -2.5845e-02, -3.5098e-01,  ..., -1.7465e+00,\n",
      "           9.0552e-01,  2.0930e+00],\n",
      "         [-8.4504e-01, -1.9173e-02, -3.5604e-01,  ..., -1.7420e+00,\n",
      "           9.2418e-01,  2.2108e+00],\n",
      "         [-8.4657e-01, -1.9836e-02, -3.5740e-01,  ..., -1.7410e+00,\n",
      "           9.2464e-01,  2.2133e+00],\n",
      "         [-3.4596e+00, -5.9707e-01,  2.0817e+00,  ...,  3.6397e+00,\n",
      "           2.0594e+01,  1.1105e+02],\n",
      "         [-1.1682e+00, -5.2790e-01, -5.5940e-01,  ..., -1.2109e+00,\n",
      "           1.6993e+00,  3.4800e+00],\n",
      "         [-1.6498e+00,  1.3746e+00,  4.5953e+00,  ...,  5.6872e+00,\n",
      "           1.8359e+01,  8.9171e+01]],\n",
      "\n",
      "        [[-8.3838e-01, -2.5951e-02, -3.5101e-01,  ..., -1.7464e+00,\n",
      "           9.0617e-01,  2.0948e+00],\n",
      "         [-8.4491e-01, -1.9203e-02, -3.5595e-01,  ..., -1.7421e+00,\n",
      "           9.2434e-01,  2.2111e+00],\n",
      "         [-3.4642e+00, -4.6416e-01,  2.0961e+00,  ...,  3.6345e+00,\n",
      "           2.0904e+01,  1.1384e+02],\n",
      "         [-1.1700e+00, -5.3118e-01, -5.5986e-01,  ..., -1.2062e+00,\n",
      "           1.7097e+00,  3.5055e+00],\n",
      "         [-1.6435e+00,  1.4433e+00,  4.6194e+00,  ...,  5.7103e+00,\n",
      "           1.8506e+01,  9.0390e+01],\n",
      "         [-1.1441e+00, -4.9023e-01, -5.4735e-01,  ..., -1.2546e+00,\n",
      "           1.6122e+00,  3.2889e+00]],\n",
      "\n",
      "        [[-8.3935e-01, -2.6009e-02, -3.5189e-01,  ..., -1.7457e+00,\n",
      "           9.0574e-01,  2.0956e+00],\n",
      "         [-3.3317e+00, -2.2266e-01,  2.2937e+00,  ...,  3.6713e+00,\n",
      "           2.1031e+01,  1.1501e+02],\n",
      "         [-1.1748e+00, -5.3775e-01, -5.6229e-01,  ..., -1.1972e+00,\n",
      "           1.7247e+00,  3.5402e+00],\n",
      "         [-1.5829e+00,  1.5272e+00,  4.7205e+00,  ...,  5.7607e+00,\n",
      "           1.8565e+01,  9.0650e+01],\n",
      "         [-1.1477e+00, -4.9477e-01, -5.4948e-01,  ..., -1.2489e+00,\n",
      "           1.6210e+00,  3.3087e+00],\n",
      "         [-8.5487e-01, -2.6386e-02, -3.6309e-01,  ..., -1.7276e+00,\n",
      "           9.3477e-01,  2.2326e+00]]], device='cuda:0'), encoder_attention=tensor([[[[0.7101, 0.1737, 0.0380, 0.0245, 0.0260, 0.0277],\n",
      "          [0.5482, 0.2198, 0.0821, 0.0484, 0.0526, 0.0488],\n",
      "          [0.0605, 0.0977, 0.1739, 0.2213, 0.2231, 0.2236],\n",
      "          [0.0481, 0.0598, 0.1038, 0.2276, 0.2674, 0.2933]],\n",
      "\n",
      "         [[0.6963, 0.1703, 0.0372, 0.0240, 0.0254, 0.0272],\n",
      "          [0.5480, 0.2197, 0.0821, 0.0484, 0.0526, 0.0488],\n",
      "          [0.0468, 0.0757, 0.1348, 0.1717, 0.1731, 0.1734],\n",
      "          [0.0040, 0.0050, 0.0086, 0.0189, 0.0223, 0.0244]],\n",
      "\n",
      "         [[0.6828, 0.1670, 0.0365, 0.0235, 0.0249, 0.0266],\n",
      "          [0.5477, 0.2196, 0.0820, 0.0484, 0.0525, 0.0488],\n",
      "          [0.0383, 0.0618, 0.1101, 0.1402, 0.1413, 0.1416],\n",
      "          [0.0021, 0.0026, 0.0045, 0.0099, 0.0116, 0.0127]],\n",
      "\n",
      "         [[0.6699, 0.1638, 0.0358, 0.0231, 0.0244, 0.0261],\n",
      "          [0.5475, 0.2195, 0.0820, 0.0484, 0.0525, 0.0487],\n",
      "          [0.0323, 0.0522, 0.0930, 0.1185, 0.1194, 0.1197],\n",
      "          [0.0014, 0.0018, 0.0031, 0.0067, 0.0079, 0.0086]],\n",
      "\n",
      "         [[0.6574, 0.1608, 0.0351, 0.0226, 0.0240, 0.0256],\n",
      "          [0.5472, 0.2194, 0.0820, 0.0483, 0.0525, 0.0487],\n",
      "          [0.0280, 0.0452, 0.0806, 0.1026, 0.1034, 0.1036],\n",
      "          [0.0011, 0.0013, 0.0023, 0.0051, 0.0059, 0.0065]],\n",
      "\n",
      "         [[0.6455, 0.1578, 0.0345, 0.0222, 0.0235, 0.0252],\n",
      "          [0.5469, 0.2193, 0.0819, 0.0483, 0.0524, 0.0487],\n",
      "          [0.0247, 0.0399, 0.0710, 0.0904, 0.0912, 0.0914],\n",
      "          [0.0009, 0.0011, 0.0019, 0.0041, 0.0048, 0.0052]]],\n",
      "\n",
      "\n",
      "        [[[0.6266, 0.2349, 0.0495, 0.0265, 0.0318, 0.0306],\n",
      "          [0.4734, 0.2470, 0.0812, 0.0648, 0.0570, 0.0766],\n",
      "          [0.0648, 0.0928, 0.1842, 0.2167, 0.2219, 0.2195],\n",
      "          [0.0641, 0.0668, 0.1033, 0.2250, 0.2883, 0.2526]],\n",
      "\n",
      "         [[0.6116, 0.2292, 0.0482, 0.0259, 0.0310, 0.0298],\n",
      "          [0.4732, 0.2468, 0.0811, 0.0647, 0.0570, 0.0766],\n",
      "          [0.0503, 0.0719, 0.1430, 0.1683, 0.1724, 0.1705],\n",
      "          [0.0049, 0.0051, 0.0079, 0.0172, 0.0221, 0.0193]],\n",
      "\n",
      "         [[0.5971, 0.2238, 0.0471, 0.0253, 0.0303, 0.0291],\n",
      "          [0.4730, 0.2467, 0.0811, 0.0647, 0.0570, 0.0765],\n",
      "          [0.0411, 0.0588, 0.1169, 0.1376, 0.1409, 0.1393],\n",
      "          [0.0025, 0.0027, 0.0041, 0.0090, 0.0115, 0.0100]],\n",
      "\n",
      "         [[0.5834, 0.2186, 0.0460, 0.0247, 0.0296, 0.0285],\n",
      "          [0.4727, 0.2466, 0.0811, 0.0647, 0.0569, 0.0765],\n",
      "          [0.0347, 0.0497, 0.0988, 0.1163, 0.1191, 0.1178],\n",
      "          [0.0017, 0.0018, 0.0028, 0.0060, 0.0077, 0.0068]],\n",
      "\n",
      "         [[0.5702, 0.2137, 0.0450, 0.0241, 0.0289, 0.0278],\n",
      "          [0.4725, 0.2464, 0.0810, 0.0646, 0.0569, 0.0764],\n",
      "          [0.0301, 0.0431, 0.0856, 0.1007, 0.1032, 0.1020],\n",
      "          [0.0013, 0.0014, 0.0021, 0.0046, 0.0059, 0.0051]],\n",
      "\n",
      "         [[0.5576, 0.2090, 0.0440, 0.0236, 0.0283, 0.0272],\n",
      "          [0.4722, 0.2463, 0.0810, 0.0646, 0.0569, 0.0764],\n",
      "          [0.0265, 0.0380, 0.0755, 0.0888, 0.0910, 0.0900],\n",
      "          [0.0010, 0.0011, 0.0017, 0.0037, 0.0047, 0.0041]]],\n",
      "\n",
      "\n",
      "        [[[0.6277, 0.2435, 0.0463, 0.0255, 0.0277, 0.0294],\n",
      "          [0.4600, 0.2572, 0.0734, 0.0612, 0.0793, 0.0689],\n",
      "          [0.0640, 0.0965, 0.1778, 0.2185, 0.2203, 0.2228],\n",
      "          [0.0678, 0.0572, 0.1238, 0.2384, 0.2436, 0.2693]],\n",
      "\n",
      "         [[0.6132, 0.2378, 0.0452, 0.0249, 0.0270, 0.0287],\n",
      "          [0.4598, 0.2571, 0.0734, 0.0611, 0.0792, 0.0689],\n",
      "          [0.0496, 0.0747, 0.1378, 0.1694, 0.1708, 0.1728],\n",
      "          [0.0049, 0.0041, 0.0090, 0.0173, 0.0176, 0.0195]],\n",
      "\n",
      "         [[0.5993, 0.2324, 0.0441, 0.0243, 0.0264, 0.0280],\n",
      "          [0.4596, 0.2570, 0.0734, 0.0611, 0.0792, 0.0688],\n",
      "          [0.0405, 0.0610, 0.1125, 0.1383, 0.1394, 0.1410],\n",
      "          [0.0025, 0.0021, 0.0047, 0.0090, 0.0091, 0.0101]],\n",
      "\n",
      "         [[0.5860, 0.2273, 0.0431, 0.0238, 0.0258, 0.0274],\n",
      "          [0.4593, 0.2568, 0.0733, 0.0611, 0.0791, 0.0688],\n",
      "          [0.0342, 0.0515, 0.0950, 0.1168, 0.1178, 0.1191],\n",
      "          [0.0017, 0.0015, 0.0031, 0.0060, 0.0062, 0.0068]],\n",
      "\n",
      "         [[0.5733, 0.2223, 0.0422, 0.0233, 0.0252, 0.0268],\n",
      "          [0.4591, 0.2567, 0.0733, 0.0611, 0.0791, 0.0688],\n",
      "          [0.0296, 0.0446, 0.0823, 0.1011, 0.1020, 0.1031],\n",
      "          [0.0013, 0.0011, 0.0024, 0.0046, 0.0047, 0.0052]],\n",
      "\n",
      "         [[0.5611, 0.2176, 0.0413, 0.0228, 0.0247, 0.0263],\n",
      "          [0.4589, 0.2566, 0.0732, 0.0610, 0.0791, 0.0687],\n",
      "          [0.0261, 0.0393, 0.0725, 0.0891, 0.0899, 0.0909],\n",
      "          [0.0010, 0.0009, 0.0019, 0.0037, 0.0037, 0.0041]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.2696, 0.1344, 0.1409, 0.1377, 0.1658, 0.1517],\n",
      "          [0.3034, 0.1683, 0.1240, 0.1642, 0.0976, 0.1425],\n",
      "          [0.1457, 0.1533, 0.1741, 0.1761, 0.1750, 0.1759],\n",
      "          [0.0375, 0.1206, 0.2036, 0.1803, 0.2622, 0.1959]],\n",
      "\n",
      "         [[0.2360, 0.1176, 0.1233, 0.1204, 0.1450, 0.1327],\n",
      "          [0.3028, 0.1679, 0.1238, 0.1639, 0.0974, 0.1422],\n",
      "          [0.1204, 0.1267, 0.1440, 0.1456, 0.1448, 0.1455],\n",
      "          [0.0053, 0.0171, 0.0288, 0.0255, 0.0371, 0.0277]],\n",
      "\n",
      "         [[0.2097, 0.1045, 0.1096, 0.1070, 0.1289, 0.1179],\n",
      "          [0.3022, 0.1676, 0.1235, 0.1635, 0.0972, 0.1419],\n",
      "          [0.1027, 0.1080, 0.1227, 0.1242, 0.1234, 0.1241],\n",
      "          [0.0029, 0.0092, 0.0155, 0.0137, 0.0200, 0.0149]],\n",
      "\n",
      "         [[0.3048, 0.1095, 0.0727, 0.0693, 0.0748, 0.0723],\n",
      "          [0.2506, 0.1646, 0.1346, 0.1705, 0.1129, 0.1527],\n",
      "          [0.0596, 0.0902, 0.0930, 0.0969, 0.0869, 0.0932],\n",
      "          [0.0154, 0.0294, 0.0128, 0.0093, 0.0101, 0.0084]],\n",
      "\n",
      "         [[0.1704, 0.0835, 0.0870, 0.0849, 0.1023, 0.0936],\n",
      "          [0.2775, 0.1530, 0.1136, 0.1512, 0.0895, 0.1312],\n",
      "          [0.0788, 0.0835, 0.0951, 0.0962, 0.0957, 0.0961],\n",
      "          [0.0019, 0.0061, 0.0103, 0.0091, 0.0133, 0.0099]],\n",
      "\n",
      "         [[0.2341, 0.0858, 0.0621, 0.0594, 0.0660, 0.0629],\n",
      "          [0.2292, 0.1497, 0.1187, 0.1502, 0.0984, 0.1338],\n",
      "          [0.0492, 0.0724, 0.0739, 0.0770, 0.0690, 0.0741],\n",
      "          [0.0100, 0.0195, 0.0091, 0.0066, 0.0073, 0.0061]]],\n",
      "\n",
      "\n",
      "        [[[0.2593, 0.1680, 0.1196, 0.1506, 0.1435, 0.1589],\n",
      "          [0.3121, 0.1171, 0.1858, 0.1113, 0.1602, 0.1136],\n",
      "          [0.1459, 0.1557, 0.1730, 0.1747, 0.1755, 0.1752],\n",
      "          [0.0372, 0.1367, 0.1638, 0.2433, 0.1856, 0.2334]],\n",
      "\n",
      "         [[0.2275, 0.1474, 0.1049, 0.1320, 0.1259, 0.1393],\n",
      "          [0.3115, 0.1168, 0.1854, 0.1111, 0.1598, 0.1133],\n",
      "          [0.1207, 0.1288, 0.1432, 0.1446, 0.1453, 0.1450],\n",
      "          [0.0053, 0.0196, 0.0235, 0.0348, 0.0266, 0.0334]],\n",
      "\n",
      "         [[0.3313, 0.1417, 0.0734, 0.0781, 0.0773, 0.0801],\n",
      "          [0.2566, 0.1231, 0.1872, 0.1259, 0.1692, 0.1284],\n",
      "          [0.0713, 0.0970, 0.1196, 0.1072, 0.1139, 0.1072],\n",
      "          [0.0224, 0.0461, 0.0170, 0.0156, 0.0121, 0.0130]],\n",
      "\n",
      "         [[0.1811, 0.1156, 0.0814, 0.1026, 0.0978, 0.1083],\n",
      "          [0.2844, 0.1057, 0.1701, 0.1017, 0.1470, 0.1039],\n",
      "          [0.0892, 0.0959, 0.1069, 0.1080, 0.1085, 0.1083],\n",
      "          [0.0028, 0.0103, 0.0123, 0.0183, 0.0139, 0.0175]],\n",
      "\n",
      "         [[0.2483, 0.1116, 0.0602, 0.0672, 0.0658, 0.0695],\n",
      "          [0.2340, 0.1108, 0.1655, 0.1097, 0.1477, 0.1114],\n",
      "          [0.0565, 0.0747, 0.0910, 0.0815, 0.0867, 0.0816],\n",
      "          [0.0129, 0.0275, 0.0107, 0.0101, 0.0078, 0.0085]],\n",
      "\n",
      "         [[0.1495, 0.0956, 0.0674, 0.0849, 0.0810, 0.0897],\n",
      "          [0.2671, 0.0994, 0.1596, 0.0955, 0.1380, 0.0975],\n",
      "          [0.0710, 0.0763, 0.0850, 0.0858, 0.0862, 0.0861],\n",
      "          [0.0019, 0.0070, 0.0084, 0.0125, 0.0095, 0.0120]]],\n",
      "\n",
      "\n",
      "        [[[0.2951, 0.1351, 0.1335, 0.1348, 0.1530, 0.1485],\n",
      "          [0.3279, 0.1511, 0.1064, 0.1627, 0.1128, 0.1391],\n",
      "          [0.1472, 0.1532, 0.1720, 0.1758, 0.1760, 0.1758],\n",
      "          [0.0291, 0.1286, 0.2327, 0.1804, 0.2313, 0.1979]],\n",
      "\n",
      "         [[0.4092, 0.1340, 0.0839, 0.0822, 0.0855, 0.0853],\n",
      "          [0.2703, 0.1511, 0.1201, 0.1723, 0.1289, 0.1527],\n",
      "          [0.0811, 0.1314, 0.1347, 0.1438, 0.1346, 0.1382],\n",
      "          [0.0343, 0.0764, 0.0386, 0.0232, 0.0238, 0.0212]],\n",
      "\n",
      "         [[0.2282, 0.1025, 0.1005, 0.1014, 0.1152, 0.1118],\n",
      "          [0.3015, 0.1377, 0.0976, 0.1504, 0.1040, 0.1286],\n",
      "          [0.1033, 0.1083, 0.1220, 0.1247, 0.1248, 0.1246],\n",
      "          [0.0039, 0.0174, 0.0314, 0.0243, 0.0312, 0.0267]],\n",
      "\n",
      "         [[0.3032, 0.1005, 0.0690, 0.0681, 0.0727, 0.0719],\n",
      "          [0.2478, 0.1377, 0.1060, 0.1514, 0.1122, 0.1333],\n",
      "          [0.0610, 0.0956, 0.0967, 0.1033, 0.0968, 0.0994],\n",
      "          [0.0154, 0.0355, 0.0192, 0.0116, 0.0121, 0.0107]],\n",
      "\n",
      "         [[0.1850, 0.0833, 0.0818, 0.0825, 0.0937, 0.0909],\n",
      "          [0.2841, 0.1299, 0.0920, 0.1416, 0.0980, 0.1211],\n",
      "          [0.0798, 0.0836, 0.0941, 0.0962, 0.0963, 0.0961],\n",
      "          [0.0021, 0.0093, 0.0168, 0.0130, 0.0167, 0.0143]],\n",
      "\n",
      "         [[0.1679, 0.0768, 0.0759, 0.0766, 0.0870, 0.0844],\n",
      "          [0.2832, 0.1305, 0.0919, 0.1405, 0.0975, 0.1201],\n",
      "          [0.0722, 0.0752, 0.0844, 0.0862, 0.0864, 0.0862],\n",
      "          [0.0015, 0.0065, 0.0118, 0.0091, 0.0117, 0.0100]]]], device='cuda:0'), decoder_attention=tensor([[[[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00]],\n",
      "\n",
      "         [[1.9710e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [4.9335e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [2.2448e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [9.1678e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00]],\n",
      "\n",
      "         [[1.9330e-02, 1.9311e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [4.9311e-04, 4.9342e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [1.8332e-01, 1.8337e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [4.7838e-01, 4.7819e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00]],\n",
      "\n",
      "         [[1.8964e-02, 1.8946e-02, 1.8946e-02, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [4.9288e-04, 4.9319e-04, 4.9319e-04, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [1.5491e-01, 1.5495e-01, 1.5495e-01, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [3.2363e-01, 3.2350e-01, 3.2350e-01, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00]],\n",
      "\n",
      "         [[1.8612e-02, 1.8594e-02, 1.8594e-02, 1.8594e-02, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [4.9265e-04, 4.9296e-04, 4.9296e-04, 4.9295e-04, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [1.3413e-01, 1.3416e-01, 1.3416e-01, 1.3416e-01, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [2.4452e-01, 2.4443e-01, 2.4443e-01, 2.4443e-01, 0.0000e+00,\n",
      "           0.0000e+00]],\n",
      "\n",
      "         [[1.8268e-02, 1.8250e-02, 1.8250e-02, 1.8250e-02, 1.8251e-02,\n",
      "           0.0000e+00],\n",
      "          [4.9240e-04, 4.9271e-04, 4.9271e-04, 4.9271e-04, 4.9270e-04,\n",
      "           0.0000e+00],\n",
      "          [1.1827e-01, 1.1830e-01, 1.1830e-01, 1.1830e-01, 1.1830e-01,\n",
      "           0.0000e+00],\n",
      "          [1.9649e-01, 1.9642e-01, 1.9642e-01, 1.9642e-01, 1.9642e-01,\n",
      "           0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00]],\n",
      "\n",
      "         [[2.4219e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [5.2238e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [2.2357e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [9.2350e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00]],\n",
      "\n",
      "         [[2.3647e-02, 2.3624e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [5.2212e-04, 5.2244e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [1.8271e-01, 1.8276e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [4.8021e-01, 4.8001e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00]],\n",
      "\n",
      "         [[2.3102e-02, 2.3079e-02, 2.3079e-02, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [5.2185e-04, 5.2218e-04, 5.2218e-04, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [1.5448e-01, 1.5452e-01, 1.5452e-01, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [3.2446e-01, 3.2433e-01, 3.2433e-01, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00]],\n",
      "\n",
      "         [[2.2576e-02, 2.2554e-02, 2.2554e-02, 2.2554e-02, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [5.2158e-04, 5.2190e-04, 5.2190e-04, 5.2190e-04, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [1.3381e-01, 1.3384e-01, 1.3384e-01, 1.3384e-01, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [2.4500e-01, 2.4490e-01, 2.4490e-01, 2.4490e-01, 0.0000e+00,\n",
      "           0.0000e+00]],\n",
      "\n",
      "         [[2.2083e-02, 2.2061e-02, 2.2062e-02, 2.2062e-02, 2.2061e-02,\n",
      "           0.0000e+00],\n",
      "          [5.2133e-04, 5.2165e-04, 5.2165e-04, 5.2165e-04, 5.2170e-04,\n",
      "           0.0000e+00],\n",
      "          [1.1801e-01, 1.1804e-01, 1.1804e-01, 1.1804e-01, 1.1804e-01,\n",
      "           0.0000e+00],\n",
      "          [1.9681e-01, 1.9673e-01, 1.9672e-01, 1.9672e-01, 1.9671e-01,\n",
      "           0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00]],\n",
      "\n",
      "         [[2.3246e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [4.9408e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [2.2495e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [9.2760e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00]],\n",
      "\n",
      "         [[2.2718e-02, 2.2696e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [4.9384e-04, 4.9415e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [1.8363e-01, 1.8368e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [4.8131e-01, 4.8112e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00]],\n",
      "\n",
      "         [[2.2209e-02, 2.2188e-02, 2.2188e-02, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [4.9360e-04, 4.9391e-04, 4.9391e-04, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [1.5514e-01, 1.5518e-01, 1.5518e-01, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [3.2497e-01, 3.2484e-01, 3.2483e-01, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00]],\n",
      "\n",
      "         [[2.1732e-02, 2.1711e-02, 2.1711e-02, 2.1711e-02, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [4.9338e-04, 4.9369e-04, 4.9369e-04, 4.9373e-04, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [1.3430e-01, 1.3433e-01, 1.3433e-01, 1.3433e-01, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [2.4529e-01, 2.4519e-01, 2.4519e-01, 2.4518e-01, 0.0000e+00,\n",
      "           0.0000e+00]],\n",
      "\n",
      "         [[2.1271e-02, 2.1250e-02, 2.1250e-02, 2.1250e-02, 2.1251e-02,\n",
      "           0.0000e+00],\n",
      "          [4.9314e-04, 4.9345e-04, 4.9345e-04, 4.9350e-04, 4.9344e-04,\n",
      "           0.0000e+00],\n",
      "          [1.1839e-01, 1.1842e-01, 1.1842e-01, 1.1842e-01, 1.1842e-01,\n",
      "           0.0000e+00],\n",
      "          [1.9699e-01, 1.9691e-01, 1.9691e-01, 1.9690e-01, 1.9691e-01,\n",
      "           0.0000e+00]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00]],\n",
      "\n",
      "         [[1.2510e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [2.0614e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [1.7294e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [8.5849e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00]],\n",
      "\n",
      "         [[1.1120e-01, 1.1111e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [2.0572e-03, 2.0582e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [1.4743e-01, 1.4747e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [4.6199e-01, 4.6185e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00]],\n",
      "\n",
      "         [[9.8861e-02, 9.8809e-02, 9.8809e-02, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [4.7199e-03, 4.7218e-03, 4.7218e-03, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [1.5999e-01, 1.6006e-01, 1.6006e-01, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [3.0470e-01, 3.0501e-01, 3.0501e-01, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00]],\n",
      "\n",
      "         [[8.8398e-02, 8.8324e-02, 8.8325e-02, 1.1331e-01, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [1.8117e-03, 1.8126e-03, 1.8126e-03, 7.8627e-02, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [1.1457e-01, 1.1459e-01, 1.1459e-01, 1.1094e-01, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [3.1451e-01, 3.1442e-01, 3.1442e-01, 5.8543e-03, 0.0000e+00,\n",
      "           0.0000e+00]],\n",
      "\n",
      "         [[7.8826e-02, 7.8777e-02, 7.8777e-02, 1.1619e-01, 7.7064e-02,\n",
      "           0.0000e+00],\n",
      "          [3.9384e-03, 3.9400e-03, 3.9400e-03, 1.0416e-01, 4.0275e-03,\n",
      "           0.0000e+00],\n",
      "          [1.2569e-01, 1.2575e-01, 1.2575e-01, 7.9408e-02, 1.2778e-01,\n",
      "           0.0000e+00],\n",
      "          [2.2194e-01, 2.2215e-01, 2.2215e-01, 4.3906e-02, 2.3136e-01,\n",
      "           0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00]],\n",
      "\n",
      "         [[1.2302e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [2.1479e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [1.7240e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [8.5676e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00]],\n",
      "\n",
      "         [[1.0911e-01, 1.0906e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [4.8382e-03, 4.8401e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [1.9183e-01, 1.9192e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [4.3663e-01, 4.3708e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00]],\n",
      "\n",
      "         [[9.5785e-02, 9.5705e-02, 1.2174e-01, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [1.8803e-03, 1.8813e-03, 8.3331e-02, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [1.2909e-01, 1.2912e-01, 1.2501e-01, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [4.5828e-01, 4.5814e-01, 8.5062e-03, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00]],\n",
      "\n",
      "         [[8.4712e-02, 8.4659e-02, 1.2517e-01, 8.2805e-02, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [4.0135e-03, 4.0151e-03, 1.0884e-01, 4.1051e-03, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [1.4447e-01, 1.4454e-01, 9.2191e-02, 1.4692e-01, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [2.8430e-01, 2.8457e-01, 5.7146e-02, 2.9655e-01, 0.0000e+00,\n",
      "           0.0000e+00]],\n",
      "\n",
      "         [[7.9276e-02, 7.9210e-02, 1.0068e-01, 7.6968e-02, 9.5741e-02,\n",
      "           0.0000e+00],\n",
      "          [1.7742e-03, 1.7751e-03, 7.8359e-02, 1.8195e-03, 5.9239e-02,\n",
      "           0.0000e+00],\n",
      "          [1.0260e-01, 1.0262e-01, 9.9348e-02, 1.0346e-01, 1.0145e-01,\n",
      "           0.0000e+00],\n",
      "          [3.1179e-01, 3.1170e-01, 5.7947e-03, 3.1280e-01, 6.7207e-03,\n",
      "           0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00]],\n",
      "\n",
      "         [[1.1985e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [4.5409e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [2.3617e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [7.8248e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00]],\n",
      "\n",
      "         [[1.0608e-01, 1.3418e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [1.7525e-03, 7.8453e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [1.4847e-01, 1.4380e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [8.4929e-01, 1.5786e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00]],\n",
      "\n",
      "         [[9.1050e-02, 1.3464e-01, 8.8958e-02, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [3.7901e-03, 1.0401e-01, 3.8783e-03, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [1.6817e-01, 1.0792e-01, 1.7109e-01, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [3.9847e-01, 8.0962e-02, 4.1605e-01, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00]],\n",
      "\n",
      "         [[8.6240e-02, 1.0899e-01, 8.3671e-02, 1.0383e-01, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [1.6605e-03, 7.4058e-02, 1.7037e-03, 5.5883e-02, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [1.1446e-01, 1.1085e-01, 1.1544e-01, 1.1324e-01, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [4.5398e-01, 8.4503e-03, 4.5548e-01, 9.7652e-03, 0.0000e+00,\n",
      "           0.0000e+00]],\n",
      "\n",
      "         [[7.9907e-02, 1.0036e-01, 7.7544e-02, 9.5749e-02, 7.7844e-02,\n",
      "           0.0000e+00],\n",
      "          [1.7213e-03, 7.4661e-02, 1.7662e-03, 5.6420e-02, 1.7607e-03,\n",
      "           0.0000e+00],\n",
      "          [1.0242e-01, 9.9198e-02, 1.0328e-01, 1.0132e-01, 1.0317e-01,\n",
      "           0.0000e+00],\n",
      "          [3.1157e-01, 5.8613e-03, 3.1262e-01, 6.7714e-03, 3.1261e-01,\n",
      "           0.0000e+00]]]], device='cuda:0'), static_variables=tensor([[[1.]],\n",
      "\n",
      "        [[1.]],\n",
      "\n",
      "        [[1.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.]],\n",
      "\n",
      "        [[1.]],\n",
      "\n",
      "        [[1.]]], device='cuda:0'), encoder_variables=tensor([[[[1.4775e-03, 4.8065e-01, 2.4383e-04,  ..., 1.4313e-03,\n",
      "           1.6673e-03, 5.7867e-03]],\n",
      "\n",
      "         [[1.1518e-03, 6.0942e-01, 1.9999e-04,  ..., 1.1345e-03,\n",
      "           1.3059e-03, 4.6164e-03]],\n",
      "\n",
      "         [[1.1792e-03, 6.0656e-01, 2.0405e-04,  ..., 1.1416e-03,\n",
      "           1.2969e-03, 4.5524e-03]],\n",
      "\n",
      "         [[1.2932e-03, 5.5522e-01, 2.1964e-04,  ..., 1.2179e-03,\n",
      "           1.4613e-03, 5.1017e-03]],\n",
      "\n",
      "         [[1.2853e-03, 5.6819e-01, 2.0402e-04,  ..., 1.2394e-03,\n",
      "           1.4191e-03, 4.8985e-03]],\n",
      "\n",
      "         [[1.2853e-03, 5.6819e-01, 2.0402e-04,  ..., 1.2394e-03,\n",
      "           1.4191e-03, 4.8985e-03]]],\n",
      "\n",
      "\n",
      "        [[[1.1518e-03, 6.0942e-01, 1.9999e-04,  ..., 1.1345e-03,\n",
      "           1.3059e-03, 4.6164e-03]],\n",
      "\n",
      "         [[1.1792e-03, 6.0656e-01, 2.0405e-04,  ..., 1.1416e-03,\n",
      "           1.2969e-03, 4.5524e-03]],\n",
      "\n",
      "         [[1.2932e-03, 5.5522e-01, 2.1964e-04,  ..., 1.2179e-03,\n",
      "           1.4613e-03, 5.1017e-03]],\n",
      "\n",
      "         [[1.2853e-03, 5.6819e-01, 2.0402e-04,  ..., 1.2394e-03,\n",
      "           1.4191e-03, 4.8985e-03]],\n",
      "\n",
      "         [[1.2853e-03, 5.6819e-01, 2.0402e-04,  ..., 1.2394e-03,\n",
      "           1.4191e-03, 4.8985e-03]],\n",
      "\n",
      "         [[9.7162e-04, 6.7982e-01, 1.7370e-04,  ..., 9.5830e-04,\n",
      "           1.0836e-03, 3.8873e-03]]],\n",
      "\n",
      "\n",
      "        [[[1.1792e-03, 6.0656e-01, 2.0405e-04,  ..., 1.1416e-03,\n",
      "           1.2969e-03, 4.5524e-03]],\n",
      "\n",
      "         [[1.2932e-03, 5.5522e-01, 2.1964e-04,  ..., 1.2179e-03,\n",
      "           1.4613e-03, 5.1017e-03]],\n",
      "\n",
      "         [[1.2853e-03, 5.6819e-01, 2.0402e-04,  ..., 1.2394e-03,\n",
      "           1.4191e-03, 4.8985e-03]],\n",
      "\n",
      "         [[1.2853e-03, 5.6819e-01, 2.0402e-04,  ..., 1.2394e-03,\n",
      "           1.4191e-03, 4.8985e-03]],\n",
      "\n",
      "         [[9.7162e-04, 6.7982e-01, 1.7370e-04,  ..., 9.5830e-04,\n",
      "           1.0836e-03, 3.8873e-03]],\n",
      "\n",
      "         [[1.0321e-03, 6.5667e-01, 1.8232e-04,  ..., 1.0143e-03,\n",
      "           1.1607e-03, 4.0916e-03]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[1.2950e-03, 5.6392e-01, 2.2258e-04,  ..., 1.2551e-03,\n",
      "           1.4081e-03, 4.9573e-03]],\n",
      "\n",
      "         [[1.2977e-03, 5.6405e-01, 2.0676e-04,  ..., 1.2575e-03,\n",
      "           1.4215e-03, 4.9299e-03]],\n",
      "\n",
      "         [[1.4308e-03, 5.0208e-01, 2.3439e-04,  ..., 1.3722e-03,\n",
      "           1.6142e-03, 5.5621e-03]],\n",
      "\n",
      "         [[1.2977e-03, 5.6405e-01, 2.0676e-04,  ..., 1.2575e-03,\n",
      "           1.4215e-03, 4.9299e-03]],\n",
      "\n",
      "         [[1.4890e-03, 4.7085e-01, 2.4887e-04,  ..., 1.4684e-03,\n",
      "           1.5404e-03, 5.9222e-03]],\n",
      "\n",
      "         [[1.2977e-03, 5.6405e-01, 2.0676e-04,  ..., 1.2575e-03,\n",
      "           1.4215e-03, 4.9299e-03]]],\n",
      "\n",
      "\n",
      "        [[[1.2977e-03, 5.6405e-01, 2.0676e-04,  ..., 1.2575e-03,\n",
      "           1.4215e-03, 4.9299e-03]],\n",
      "\n",
      "         [[1.4308e-03, 5.0208e-01, 2.3439e-04,  ..., 1.3722e-03,\n",
      "           1.6142e-03, 5.5621e-03]],\n",
      "\n",
      "         [[1.2977e-03, 5.6405e-01, 2.0676e-04,  ..., 1.2575e-03,\n",
      "           1.4215e-03, 4.9299e-03]],\n",
      "\n",
      "         [[1.4890e-03, 4.7085e-01, 2.4887e-04,  ..., 1.4684e-03,\n",
      "           1.5404e-03, 5.9222e-03]],\n",
      "\n",
      "         [[1.2977e-03, 5.6405e-01, 2.0676e-04,  ..., 1.2575e-03,\n",
      "           1.4215e-03, 4.9299e-03]],\n",
      "\n",
      "         [[1.4011e-03, 5.0641e-01, 2.3490e-04,  ..., 1.3771e-03,\n",
      "           1.4799e-03, 5.5853e-03]]],\n",
      "\n",
      "\n",
      "        [[[1.4308e-03, 5.0208e-01, 2.3439e-04,  ..., 1.3722e-03,\n",
      "           1.6142e-03, 5.5621e-03]],\n",
      "\n",
      "         [[1.2977e-03, 5.6405e-01, 2.0676e-04,  ..., 1.2575e-03,\n",
      "           1.4215e-03, 4.9299e-03]],\n",
      "\n",
      "         [[1.4890e-03, 4.7085e-01, 2.4887e-04,  ..., 1.4684e-03,\n",
      "           1.5404e-03, 5.9222e-03]],\n",
      "\n",
      "         [[1.2977e-03, 5.6405e-01, 2.0676e-04,  ..., 1.2575e-03,\n",
      "           1.4215e-03, 4.9299e-03]],\n",
      "\n",
      "         [[1.4011e-03, 5.0641e-01, 2.3490e-04,  ..., 1.3771e-03,\n",
      "           1.4799e-03, 5.5853e-03]],\n",
      "\n",
      "         [[1.2977e-03, 5.6405e-01, 2.0676e-04,  ..., 1.2575e-03,\n",
      "           1.4215e-03, 4.9299e-03]]]], device='cuda:0'), decoder_variables=tensor([[[[9.9673e-08, 3.9322e-07, 5.3007e-06,  ..., 1.0872e-07,\n",
      "           2.1781e-08, 2.4884e-08]],\n",
      "\n",
      "         [[5.5425e-08, 6.1140e-08, 1.3436e-06,  ..., 4.5424e-08,\n",
      "           1.4469e-08, 1.4278e-08]],\n",
      "\n",
      "         [[4.6207e-08, 6.9117e-08, 3.5008e-07,  ..., 1.0145e-07,\n",
      "           1.8519e-08, 1.1953e-08]],\n",
      "\n",
      "         [[6.0663e-08, 4.7148e-08, 1.5520e-06,  ..., 6.8307e-08,\n",
      "           1.6895e-08, 1.5852e-08]],\n",
      "\n",
      "         [[4.6207e-08, 6.9117e-08, 3.5008e-07,  ..., 1.0145e-07,\n",
      "           1.8519e-08, 1.1953e-08]],\n",
      "\n",
      "         [[1.0097e-06, 8.6772e-05, 9.8051e-05,  ..., 5.7917e-07,\n",
      "           1.6803e-07, 2.8558e-07]]],\n",
      "\n",
      "\n",
      "        [[[5.5425e-08, 6.1140e-08, 1.3436e-06,  ..., 4.5424e-08,\n",
      "           1.4469e-08, 1.4278e-08]],\n",
      "\n",
      "         [[4.6207e-08, 6.9117e-08, 3.5008e-07,  ..., 1.0145e-07,\n",
      "           1.8519e-08, 1.1953e-08]],\n",
      "\n",
      "         [[6.0663e-08, 4.7148e-08, 1.5520e-06,  ..., 6.8307e-08,\n",
      "           1.6895e-08, 1.5852e-08]],\n",
      "\n",
      "         [[4.6207e-08, 6.9117e-08, 3.5008e-07,  ..., 1.0145e-07,\n",
      "           1.8519e-08, 1.1953e-08]],\n",
      "\n",
      "         [[1.0097e-06, 8.6772e-05, 9.8051e-05,  ..., 5.7917e-07,\n",
      "           1.6803e-07, 2.8558e-07]],\n",
      "\n",
      "         [[9.5615e-08, 4.0235e-07, 2.9143e-06,  ..., 4.0776e-08,\n",
      "           1.9906e-08, 1.9196e-08]]],\n",
      "\n",
      "\n",
      "        [[[4.6207e-08, 6.9117e-08, 3.5008e-07,  ..., 1.0145e-07,\n",
      "           1.8519e-08, 1.1953e-08]],\n",
      "\n",
      "         [[6.0663e-08, 4.7148e-08, 1.5520e-06,  ..., 6.8307e-08,\n",
      "           1.6895e-08, 1.5852e-08]],\n",
      "\n",
      "         [[4.6207e-08, 6.9117e-08, 3.5008e-07,  ..., 1.0145e-07,\n",
      "           1.8519e-08, 1.1953e-08]],\n",
      "\n",
      "         [[1.0097e-06, 8.6772e-05, 9.8051e-05,  ..., 5.7917e-07,\n",
      "           1.6803e-07, 2.8558e-07]],\n",
      "\n",
      "         [[9.5615e-08, 4.0235e-07, 2.9143e-06,  ..., 4.0776e-08,\n",
      "           1.9906e-08, 1.9196e-08]],\n",
      "\n",
      "         [[4.6207e-08, 6.9117e-08, 3.5008e-07,  ..., 1.0145e-07,\n",
      "           1.8519e-08, 1.1953e-08]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[4.7150e-08, 1.3200e-08, 7.4011e-07,  ..., 4.8608e-08,\n",
      "           1.5029e-08, 1.1355e-08]],\n",
      "\n",
      "         [[3.2580e-08, 5.1573e-08, 1.1947e-07,  ..., 5.6604e-08,\n",
      "           1.6427e-08, 8.7152e-09]],\n",
      "\n",
      "         [[2.9602e-08, 4.8206e-08, 8.7901e-08,  ..., 4.0683e-08,\n",
      "           1.4963e-08, 8.2304e-09]],\n",
      "\n",
      "         [[9.5358e-04, 8.6651e-01, 4.1128e-03,  ..., 9.7232e-05,\n",
      "           6.0197e-04, 6.9526e-04]],\n",
      "\n",
      "         [[2.9581e-08, 4.7753e-08, 2.7132e-08,  ..., 1.3740e-08,\n",
      "           1.7746e-08, 8.2757e-09]],\n",
      "\n",
      "         [[7.1678e-04, 8.9822e-01, 5.5320e-03,  ..., 8.3359e-05,\n",
      "           4.5153e-04, 5.2186e-04]]],\n",
      "\n",
      "\n",
      "        [[[3.2580e-08, 5.1573e-08, 1.1947e-07,  ..., 5.6604e-08,\n",
      "           1.6427e-08, 8.7152e-09]],\n",
      "\n",
      "         [[2.9602e-08, 4.8206e-08, 8.7901e-08,  ..., 4.0683e-08,\n",
      "           1.4963e-08, 8.2304e-09]],\n",
      "\n",
      "         [[9.5358e-04, 8.6651e-01, 4.1128e-03,  ..., 9.7232e-05,\n",
      "           6.0197e-04, 6.9526e-04]],\n",
      "\n",
      "         [[2.9581e-08, 4.7753e-08, 2.7132e-08,  ..., 1.3740e-08,\n",
      "           1.7746e-08, 8.2757e-09]],\n",
      "\n",
      "         [[7.1678e-04, 8.9822e-01, 5.5320e-03,  ..., 8.3359e-05,\n",
      "           4.5153e-04, 5.2186e-04]],\n",
      "\n",
      "         [[6.9744e-08, 2.2679e-07, 2.6908e-06,  ..., 4.8702e-08,\n",
      "           1.5624e-08, 1.7379e-08]]],\n",
      "\n",
      "\n",
      "        [[[2.9602e-08, 4.8206e-08, 8.7901e-08,  ..., 4.0683e-08,\n",
      "           1.4963e-08, 8.2304e-09]],\n",
      "\n",
      "         [[9.5358e-04, 8.6651e-01, 4.1128e-03,  ..., 9.7232e-05,\n",
      "           6.0197e-04, 6.9526e-04]],\n",
      "\n",
      "         [[2.9581e-08, 4.7753e-08, 2.7132e-08,  ..., 1.3740e-08,\n",
      "           1.7746e-08, 8.2757e-09]],\n",
      "\n",
      "         [[7.1678e-04, 8.9822e-01, 5.5320e-03,  ..., 8.3359e-05,\n",
      "           4.5153e-04, 5.2186e-04]],\n",
      "\n",
      "         [[6.9744e-08, 2.2679e-07, 2.6908e-06,  ..., 4.8702e-08,\n",
      "           1.5624e-08, 1.7379e-08]],\n",
      "\n",
      "         [[3.9957e-08, 6.2558e-08, 3.3361e-07,  ..., 5.8569e-08,\n",
      "           1.5799e-08, 1.0516e-08]]]], device='cuda:0'), decoder_lengths=tensor([6, 6, 6,  ..., 6, 6, 6], device='cuda:0'), encoder_lengths=tensor([6, 6, 6,  ..., 6, 6, 6], device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "print(test_predictions.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_val_targets = val_dataloader.dataset.data[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation prediction\n",
      "tensor([[[  1.7168,   2.7723,   2.3146,  ...,   0.6925,   3.9043,   5.4367],\n",
      "         [  1.7195,   2.7847,   2.3201,  ...,   0.6955,   3.9341,   5.5801],\n",
      "         [  1.7204,   2.7853,   2.3219,  ...,   0.6976,   3.9377,   5.5843],\n",
      "         [  1.7214,   2.7858,   2.3234,  ...,   0.6984,   3.9395,   5.5849],\n",
      "         [  1.7224,   2.7864,   2.3248,  ...,   0.6991,   3.9409,   5.5847],\n",
      "         [  1.7233,   2.7869,   2.3259,  ...,   0.6993,   3.9416,   5.5840]],\n",
      "\n",
      "        [[  1.7162,   2.7719,   2.3139,  ...,   0.6920,   3.9030,   5.4349],\n",
      "         [  1.7197,   2.7850,   2.3205,  ...,   0.6958,   3.9344,   5.5803],\n",
      "         [  1.7207,   2.7854,   2.3222,  ...,   0.6974,   3.9376,   5.5837],\n",
      "         [  1.7217,   2.7860,   2.3238,  ...,   0.6985,   3.9398,   5.5848],\n",
      "         [  1.7227,   2.7865,   2.3251,  ...,   0.6990,   3.9410,   5.5846],\n",
      "         [  1.7237,   2.7870,   2.3263,  ...,   0.6991,   3.9417,   5.5836]],\n",
      "\n",
      "        [[  1.7190,   2.7737,   2.3177,  ...,   0.6936,   3.9082,   5.4416],\n",
      "         [  1.7217,   2.7861,   2.3231,  ...,   0.6965,   3.9371,   5.5826],\n",
      "         [  1.7228,   2.7867,   2.3250,  ...,   0.6983,   3.9404,   5.5859],\n",
      "         [  1.7239,   2.7872,   2.3265,  ...,   0.6990,   3.9422,   5.5865],\n",
      "         [  1.7250,   2.7878,   2.3278,  ...,   0.6994,   3.9433,   5.5860],\n",
      "         [  1.7260,   2.7884,   2.3292,  ...,   0.6998,   3.9444,   5.5854]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  1.1949,   5.1285,   9.0892,  ...,  10.0341,  25.5388, 108.0271],\n",
      "         [  1.4494,   2.2725,   2.1814,  ...,   1.2523,   4.7577,   6.7390],\n",
      "         [  1.7794,   2.8089,   2.3914,  ...,   0.7065,   3.9869,   5.5634],\n",
      "         [  1.7825,   2.8129,   2.3924,  ...,   0.6963,   3.9786,   5.5517],\n",
      "         [  1.7820,   2.8130,   2.3918,  ...,   0.6959,   3.9773,   5.5503],\n",
      "         [  1.7816,   2.8130,   2.3913,  ...,   0.6959,   3.9767,   5.5499]],\n",
      "\n",
      "        [[  1.7904,   2.8068,   2.3981,  ...,   0.6903,   3.9536,   5.4136],\n",
      "         [  1.7830,   2.8145,   2.3926,  ...,   0.6946,   3.9780,   5.5606],\n",
      "         [  1.7814,   2.8136,   2.3913,  ...,   0.6961,   3.9794,   5.5647],\n",
      "         [  1.7806,   2.8131,   2.3906,  ...,   0.6969,   3.9799,   5.5656],\n",
      "         [  1.7800,   2.8128,   2.3900,  ...,   0.6971,   3.9798,   5.5653],\n",
      "         [  1.7796,   2.8126,   2.3896,  ...,   0.6973,   3.9794,   5.5645]],\n",
      "\n",
      "        [[  1.7867,   2.8052,   2.3948,  ...,   0.6925,   3.9547,   5.4196],\n",
      "         [  1.7796,   2.8133,   2.3894,  ...,   0.6963,   3.9779,   5.5655],\n",
      "         [  1.7784,   2.8126,   2.3884,  ...,   0.6975,   3.9789,   5.5683],\n",
      "         [  1.7777,   2.8122,   2.3878,  ...,   0.6980,   3.9792,   5.5687],\n",
      "         [  1.7773,   2.8120,   2.3874,  ...,   0.6982,   3.9790,   5.5681],\n",
      "         [  1.7770,   2.8118,   2.3871,  ...,   0.6982,   3.9787,   5.5672]]],\n",
      "       device='cuda:0')\n",
      "Validation target\n",
      "[tensor([0., 0., 0.,  ..., 0., 0., 0.])]\n"
     ]
    }
   ],
   "source": [
    "print(\"Validation prediction\")\n",
    "print(val_predictions.output.prediction)\n",
    "print(\"Validation target\")\n",
    "print(actual_val_targets)\n",
    "\n",
    "print(f\"RMSE{RMSE()(val_predictions.output.prediction, actual_val_targets)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
