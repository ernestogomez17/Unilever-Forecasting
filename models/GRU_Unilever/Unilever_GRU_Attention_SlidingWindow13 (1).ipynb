{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "e8r5EgJur6M3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from torch.utils.data import DataLoader, TensorDataset, Subset\n",
        "import sklearn.metrics as sk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1ATXQJXr_xt",
        "outputId": "dee89a8d-1656-439c-b417-8d203fec01bc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.load(\"/content/drive/MyDrive/Unilever Datasets, Sliding Window 13/HEALTHY SNACKING_dataset_processed (1).npz\")"
      ],
      "metadata": {
        "id": "tbmLmJXGsC1G"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Extract the arrays\n",
        "X = data['X']  # Shape: (timesteps, input_sequence_length, nodes, features)\n",
        "Y = data['Y']  # Shape: (timesteps, output_sequence_length, nodes, features)\n",
        "\n",
        "# Drop all features except the first one for both X and Y\n",
        "X = X[:, :, :, :1]  # Keep only the first feature\n",
        "Y = Y[:, :, :, :1]  # Keep only the first feature\n"
      ],
      "metadata": {
        "id": "jpxlOZ5psE45"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape Y to match the output format, if necessary\n",
        "# Y is expected to have shape (timestep/index, prediction window, nodes, 1)\n",
        "# If Y's shape is already correct, skip this step\n",
        "X = X.squeeze(-1)\n",
        "Y = Y.squeeze(-1)  # Remove the last dimension"
      ],
      "metadata": {
        "id": "lBI1WwzfLJOH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Y shape after squeezing:\", Y.shape)\n",
        "print(\"Y sample:\", Y[:5])  # Print a small portion of Y to verify\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmGCSZPSSkev",
        "outputId": "2bdf5fc2-6a53-4dcf-f4f5-c1aee661ff37"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Y shape after squeezing: (167, 13, 1082)\n",
            "Y sample: [[[360. 360.   0. ...   0.   0.   0.]\n",
            "  [360. 360.   2. ...   0.   0.   0.]\n",
            "  [120. 120.   0. ...   0.   0.   0.]\n",
            "  ...\n",
            "  [  0. 240.   0. ...   0.   0.   0.]\n",
            "  [  0.   0.   0. ...   0.   0.   0.]\n",
            "  [  0.   0.   0. ...   0.   0.   0.]]\n",
            "\n",
            " [[360. 360.   2. ...   0.   0.   0.]\n",
            "  [120. 120.   0. ...   0.   0.   0.]\n",
            "  [  0. 480.   0. ...   0.   0.   0.]\n",
            "  ...\n",
            "  [  0.   0.   0. ...   0.   0.   0.]\n",
            "  [  0.   0.   0. ...   0.   0.   0.]\n",
            "  [  0.   0.   0. ...   0.   0.   0.]]\n",
            "\n",
            " [[120. 120.   0. ...   0.   0.   0.]\n",
            "  [  0. 480.   0. ...   0.   0.   0.]\n",
            "  [360.   0.   0. ...   0.   0.   0.]\n",
            "  ...\n",
            "  [  0.   0.   0. ...   0.   0.   0.]\n",
            "  [  0.   0.   0. ...   0.   0.   0.]\n",
            "  [  0.   0.   0. ...   0.   0.   0.]]\n",
            "\n",
            " [[  0. 480.   0. ...   0.   0.   0.]\n",
            "  [360.   0.   0. ...   0.   0.   0.]\n",
            "  [  0. 600.   0. ...   0.   0.   0.]\n",
            "  ...\n",
            "  [  0.   0.   0. ...   0.   0.   0.]\n",
            "  [  0.   0.   0. ...   0.   0.   0.]\n",
            "  [  0.   0.   3. ...   0.   0.   0.]]\n",
            "\n",
            " [[360.   0.   0. ...   0.   0.   0.]\n",
            "  [  0. 600.   0. ...   0.   0.   0.]\n",
            "  [360. 480.   0. ...   0.   0.   0.]\n",
            "  ...\n",
            "  [  0.   0.   0. ...   0.   0.   0.]\n",
            "  [  0.   0.   3. ...   0.   0.   0.]\n",
            "  [  0.   0.   0. ...   0.   0.   0.]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify that the input and output sequence lengths are 13\n",
        "assert X.shape[1] == 13, f\"Expected input sequence length of 13, got {X.shape[1]}\"\n",
        "assert Y.shape[1] == 13, f\"Expected output sequence length of 13, got {Y.shape[1]}\"\n",
        "\n",
        "# Split the data into train, validation, and test sets (70%, 15%, 15%)\n",
        "train_size = int(len(X) * 0.7)\n",
        "val_size = int(len(X) * 0.15)\n",
        "test_size = len(X) - train_size - val_size\n",
        "\n",
        "X_train, X_val, X_test = X[:train_size], X[train_size:train_size + val_size], X[train_size + val_size:]\n",
        "y_train, y_val, y_test = Y[:train_size], Y[train_size:train_size + val_size], Y[train_size + val_size:]\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
        "X_val = torch.tensor(X_val, dtype=torch.float32)\n",
        "y_val = torch.tensor(y_val, dtype=torch.float32)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test = torch.tensor(y_test, dtype=torch.float32)\n",
        "\n",
        "# Print shapes to verify\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"X_val shape:\", X_val.shape)\n",
        "print(\"y_val shape:\", y_val.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_test shape:\", y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shNXGNyDISAt",
        "outputId": "5992be9f-b9c8-44e0-82a3-8d09c625d0ef"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: torch.Size([116, 13, 1082])\n",
            "y_train shape: torch.Size([116, 13, 1082])\n",
            "X_val shape: torch.Size([25, 13, 1082])\n",
            "y_val shape: torch.Size([25, 13, 1082])\n",
            "X_test shape: torch.Size([26, 13, 1082])\n",
            "y_test shape: torch.Size([26, 13, 1082])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the GRU model with Attention\n",
        "class AirModelWithAttention(nn.Module):\n",
        "    def __init__(self, input_sz, hidden_sz, output_sz, n_steps, dropout_prob=0.1):\n",
        "        super().__init__()\n",
        "        self.hidden_sz = hidden_sz\n",
        "        self.gru = nn.GRU(\n",
        "            input_size=input_sz,\n",
        "            hidden_size=hidden_sz,\n",
        "            num_layers=2,\n",
        "            batch_first=True,\n",
        "            bidirectional=False\n",
        "        )\n",
        "        self.dropout = nn.Dropout(p=dropout_prob)\n",
        "\n",
        "        # Attention layer\n",
        "        self.attention = nn.Linear(hidden_sz, 1)\n",
        "\n",
        "        # Output layer\n",
        "        self.linear = nn.Linear(hidden_sz, output_sz * n_steps)\n",
        "        self.output_sz = output_sz\n",
        "        self.n_steps = n_steps\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [batch_size, seq_length, input_size]\n",
        "        gru_output, _ = self.gru(x)  # gru_output: [batch_size, seq_length, hidden_sz]\n",
        "\n",
        "        # Apply attention\n",
        "        # Compute attention scores\n",
        "        attn_scores = self.attention(gru_output)  # attn_scores: [batch_size, seq_length, 1]\n",
        "        attn_scores = attn_scores.squeeze(-1)     # attn_scores: [batch_size, seq_length]\n",
        "\n",
        "        # Normalize attention scores to get attention weights\n",
        "        attn_weights = torch.softmax(attn_scores, dim=1)  # attn_weights: [batch_size, seq_length]\n",
        "\n",
        "        # Compute context vector as weighted sum of GRU outputs\n",
        "        context_vector = torch.sum(gru_output * attn_weights.unsqueeze(-1), dim=1)  # context_vector: [batch_size, hidden_sz]\n",
        "\n",
        "        # Apply dropout\n",
        "        context_vector = self.dropout(context_vector)\n",
        "\n",
        "        # Pass context vector through the output layer\n",
        "        output = self.linear(context_vector)\n",
        "        output = torch.relu(output)\n",
        "\n",
        "        # Reshape output to match the desired format\n",
        "        output = output.view(-1, self.n_steps, self.output_sz)\n",
        "        return output\n"
      ],
      "metadata": {
        "id": "BkYlFcIssFEy"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model parameters\n",
        "input_size = X_train.shape[2]\n",
        "output_size = y_train.shape[2]\n",
        "model = AirModelWithAttention(\n",
        "    input_sz=input_size,\n",
        "    hidden_sz=50,\n",
        "    output_sz=output_size,\n",
        "    n_steps=13,  # Updated to match the forecasting window\n",
        "    dropout_prob=0.1  # Added dropout for regularization\n",
        ")\n",
        "\n",
        "# Optimizer and loss function\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Reduced learning rate for stability\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "# Prepare the data loader\n",
        "train_data = TensorDataset(X_train, y_train)\n",
        "train_loader = DataLoader(train_data, batch_size=16, shuffle=False)\n",
        "\n",
        "# Lists to store metrics\n",
        "train_metrics = {'RMSE': [], 'MAE': [], 'R2': [], 'MSE': [], 'MAPE': [], 'WMAPE': []}\n",
        "val_metrics = {'RMSE': [], 'MAE': [], 'R2': [], 'MSE': [], 'MAPE': [], 'WMAPE': []}\n",
        "test_metrics = {'RMSE': [], 'MAE': [], 'R2': [], 'MSE': [], 'MAPE': [], 'WMAPE': []}\n",
        "\n",
        "# Function to calculate WMAPE\n",
        "def wmape(y_true, y_pred):\n",
        "    y_true = y_true.flatten()\n",
        "    y_pred = y_pred.flatten()\n",
        "    return np.sum(np.abs(y_true - y_pred)) / np.sum(np.abs(y_true))\n",
        "\n",
        "# Function to calculate MAPE assuming there are y_actuals that are equal to 0\n",
        "# def mape(y_true, y_pred):\n",
        "#     y_true = y_true.flatten()\n",
        "#     y_pred = y_pred.flatten()\n",
        "#     # Create a mask for non-zero actuals\n",
        "#     mask = y_true != 0\n",
        "#     # Ensure there are non-zero actuals to prevent division by zero in the mean\n",
        "#     if np.sum(mask) == 0:\n",
        "#         return np.nan  # Or handle appropriately\n",
        "#     # Compute MAPE only on non-zero actuals\n",
        "#     return np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100\n",
        "\n",
        "\n",
        "def mape(y_true, y_pred):\n",
        "    y_true = y_true.flatten()\n",
        "    y_pred = y_pred.flatten()\n",
        "    return np.mean(np.abs((y_true - y_pred) / (y_true + 1e-8))) * 100  # Added 1e-8 to avoid division by zero\n",
        "\n",
        "# Training loop\n",
        "n_epochs = 500  # Reduced epochs for faster training during testing\n",
        "for epoch in range(n_epochs):\n",
        "    model.train()\n",
        "    for X_batch, y_batch in train_loader:\n",
        "        y_pred = model(X_batch)\n",
        "        loss = loss_fn(y_pred, y_batch)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    # Validation every epoch\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # Helper function to calculate metrics\n",
        "        def calculate_metrics(y_true, y_pred, n):\n",
        "            y_true = y_true[:, :n, :].cpu().numpy()\n",
        "            y_pred = y_pred[:, :n, :].cpu().numpy()\n",
        "\n",
        "            mse = mean_squared_error(y_true.flatten(), y_pred.flatten())\n",
        "            rmse = np.sqrt(mse)\n",
        "            mae = mean_absolute_error(y_true.flatten(), y_pred.flatten())\n",
        "            r2 = r2_score(y_true.flatten(), y_pred.flatten())\n",
        "            mape_value = mape(y_true, y_pred)\n",
        "            wmape_value = wmape(y_true, y_pred) * 100  # Expressed as percentage\n",
        "            return mse, rmse, mae, r2, mape_value, wmape_value\n",
        "\n",
        "        # Training metrics\n",
        "        y_pred_train = model(X_train)\n",
        "        mse_train, rmse_train, mae_train, r2_train, mape_train, wmape_train = calculate_metrics(y_train, y_pred_train, 13)\n",
        "        train_metrics['MSE'].append(mse_train)\n",
        "        train_metrics['RMSE'].append(rmse_train)\n",
        "        train_metrics['MAE'].append(mae_train)\n",
        "        train_metrics['R2'].append(r2_train)\n",
        "        train_metrics['MAPE'].append(mape_train)\n",
        "        train_metrics['WMAPE'].append(wmape_train)\n",
        "\n",
        "        # Validation metrics\n",
        "        y_pred_val = model(X_val)\n",
        "        mse_val, rmse_val, mae_val, r2_val, mape_val, wmape_val = calculate_metrics(y_val, y_pred_val, 13)\n",
        "        val_metrics['MSE'].append(mse_val)\n",
        "        val_metrics['RMSE'].append(rmse_val)\n",
        "        val_metrics['MAE'].append(mae_val)\n",
        "        val_metrics['R2'].append(r2_val)\n",
        "        val_metrics['MAPE'].append(mape_val)\n",
        "        val_metrics['WMAPE'].append(wmape_val)\n",
        "\n",
        "        # Testing metrics\n",
        "        y_pred_test = model(X_test)\n",
        "        mse_test, rmse_test, mae_test, r2_test, mape_test, wmape_test = calculate_metrics(y_test, y_pred_test, 13)\n",
        "        test_metrics['MSE'].append(mse_test)\n",
        "        test_metrics['RMSE'].append(rmse_test)\n",
        "        test_metrics['MAE'].append(mae_test)\n",
        "        test_metrics['R2'].append(r2_test)\n",
        "        test_metrics['MAPE'].append(mape_test)\n",
        "        test_metrics['WMAPE'].append(wmape_test)\n",
        "\n",
        "    # Print metrics every 10 epochs\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f\"Epoch {epoch+1}/{n_epochs}\")\n",
        "        print(f\"Train - RMSE: {rmse_train:.4f}, MAE: {mae_train:.4f}, R²: {r2_train:.4f}, MAPE: {mape_train:.2f}%, WMAPE: {wmape_train:.2f}%\")\n",
        "        print(f\"Val   - RMSE: {rmse_val:.4f}, MAE: {mae_val:.4f}, R²: {r2_val:.4f}, MAPE: {mape_val:.2f}%, WMAPE: {wmape_val:.2f}%\")\n",
        "        print(f\"Test  - RMSE: {rmse_test:.4f}, MAE: {mae_test:.4f}, R²: {r2_test:.4f}, MAPE: {mape_test:.2f}%, WMAPE: {wmape_test:.2f}%\")\n",
        "        print(\"-\" * 80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SewJF72sFHY",
        "outputId": "2f7311ee-63fb-48ee-d7ef-58c3ded537f0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/500\n",
            "Train - RMSE: 1282.7178, MAE: 206.7598, R²: -0.0257, MAPE: 6720681600.00%, WMAPE: 100.14%\n",
            "Val   - RMSE: 1404.7418, MAE: 196.9530, R²: -0.0193, MAPE: 6915850400.00%, WMAPE: 100.16%\n",
            "Test  - RMSE: 870.9332, MAE: 92.2183, R²: -0.0104, MAPE: 8758422400.00%, WMAPE: 100.77%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 20/500\n",
            "Train - RMSE: 1282.1152, MAE: 206.9928, R²: -0.0247, MAPE: 13036397600.00%, WMAPE: 100.25%\n",
            "Val   - RMSE: 1404.2572, MAE: 197.2117, R²: -0.0186, MAPE: 13367412000.00%, WMAPE: 100.29%\n",
            "Test  - RMSE: 870.5742, MAE: 92.9066, R²: -0.0095, MAPE: 17414747200.00%, WMAPE: 101.52%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 30/500\n",
            "Train - RMSE: 1281.5521, MAE: 207.1897, R²: -0.0238, MAPE: 18655955200.00%, WMAPE: 100.34%\n",
            "Val   - RMSE: 1403.8041, MAE: 197.4288, R²: -0.0179, MAPE: 19097433600.00%, WMAPE: 100.40%\n",
            "Test  - RMSE: 870.2415, MAE: 93.5151, R²: -0.0088, MAPE: 25125977600.00%, WMAPE: 102.19%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 40/500\n",
            "Train - RMSE: 1281.0070, MAE: 207.3680, R²: -0.0229, MAPE: 23914913600.00%, WMAPE: 100.43%\n",
            "Val   - RMSE: 1403.3657, MAE: 197.6259, R²: -0.0173, MAPE: 24457240000.00%, WMAPE: 100.50%\n",
            "Test  - RMSE: 869.9221, MAE: 94.0843, R²: -0.0080, MAPE: 32365036800.00%, WMAPE: 102.81%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 50/500\n",
            "Train - RMSE: 1280.4746, MAE: 207.5341, R²: -0.0221, MAPE: 28932416000.00%, WMAPE: 100.51%\n",
            "Val   - RMSE: 1402.9386, MAE: 197.8119, R²: -0.0167, MAPE: 29578588800.00%, WMAPE: 100.60%\n",
            "Test  - RMSE: 869.6116, MAE: 94.6265, R²: -0.0073, MAPE: 39269059200.00%, WMAPE: 103.40%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 60/500\n",
            "Train - RMSE: 1279.9484, MAE: 207.6894, R²: -0.0212, MAPE: 33764217600.00%, WMAPE: 100.59%\n",
            "Val   - RMSE: 1402.5168, MAE: 197.9865, R²: -0.0161, MAPE: 34506419200.00%, WMAPE: 100.69%\n",
            "Test  - RMSE: 869.3065, MAE: 95.1517, R²: -0.0066, MAPE: 45962083200.00%, WMAPE: 103.98%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 70/500\n",
            "Train - RMSE: 1279.4264, MAE: 207.8354, R²: -0.0204, MAPE: 38445043200.00%, WMAPE: 100.66%\n",
            "Val   - RMSE: 1402.0983, MAE: 198.1520, R²: -0.0155, MAPE: 39279145600.00%, WMAPE: 100.77%\n",
            "Test  - RMSE: 869.0058, MAE: 95.6633, R²: -0.0059, MAPE: 52495846400.00%, WMAPE: 104.54%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 80/500\n",
            "Train - RMSE: 1278.9103, MAE: 207.9730, R²: -0.0196, MAPE: 42985622400.00%, WMAPE: 100.72%\n",
            "Val   - RMSE: 1401.6838, MAE: 198.3088, R²: -0.0149, MAPE: 43910537600.00%, WMAPE: 100.85%\n",
            "Test  - RMSE: 868.7094, MAE: 96.1609, R²: -0.0052, MAPE: 58862329600.00%, WMAPE: 105.08%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 90/500\n",
            "Train - RMSE: 1278.3964, MAE: 208.1021, R²: -0.0188, MAPE: 47410640000.00%, WMAPE: 100.79%\n",
            "Val   - RMSE: 1401.2722, MAE: 198.4597, R²: -0.0143, MAPE: 48433977600.00%, WMAPE: 100.93%\n",
            "Test  - RMSE: 868.4161, MAE: 96.6478, R²: -0.0045, MAPE: 65098252800.00%, WMAPE: 105.61%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 100/500\n",
            "Train - RMSE: 1277.8873, MAE: 208.2253, R²: -0.0179, MAPE: 51717689600.00%, WMAPE: 100.85%\n",
            "Val   - RMSE: 1400.8646, MAE: 198.6039, R²: -0.0137, MAPE: 52834899200.00%, WMAPE: 101.00%\n",
            "Test  - RMSE: 868.1270, MAE: 97.1221, R²: -0.0039, MAPE: 71180646400.00%, WMAPE: 106.13%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 110/500\n",
            "Train - RMSE: 1277.3801, MAE: 208.3416, R²: -0.0171, MAPE: 55917062400.00%, WMAPE: 100.90%\n",
            "Val   - RMSE: 1400.4594, MAE: 198.7426, R²: -0.0131, MAPE: 57132345600.00%, WMAPE: 101.07%\n",
            "Test  - RMSE: 867.8409, MAE: 97.5855, R²: -0.0032, MAPE: 77131852800.00%, WMAPE: 106.64%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 120/500\n",
            "Train - RMSE: 1276.8767, MAE: 208.4518, R²: -0.0163, MAPE: 60011232000.00%, WMAPE: 100.96%\n",
            "Val   - RMSE: 1400.0575, MAE: 198.8759, R²: -0.0125, MAPE: 61326944000.00%, WMAPE: 101.14%\n",
            "Test  - RMSE: 867.5586, MAE: 98.0382, R²: -0.0025, MAPE: 82952531200.00%, WMAPE: 107.13%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 130/500\n",
            "Train - RMSE: 1276.3778, MAE: 208.5568, R²: -0.0155, MAPE: 64012716800.00%, WMAPE: 101.01%\n",
            "Val   - RMSE: 1399.6598, MAE: 199.0048, R²: -0.0119, MAPE: 65431987200.00%, WMAPE: 101.21%\n",
            "Test  - RMSE: 867.2802, MAE: 98.4812, R²: -0.0019, MAPE: 88657632000.00%, WMAPE: 107.61%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 140/500\n",
            "Train - RMSE: 1275.8811, MAE: 208.6567, R²: -0.0148, MAPE: 67937369600.00%, WMAPE: 101.05%\n",
            "Val   - RMSE: 1399.2639, MAE: 199.1290, R²: -0.0114, MAPE: 69461465600.00%, WMAPE: 101.27%\n",
            "Test  - RMSE: 867.0046, MAE: 98.9164, R²: -0.0013, MAPE: 94269324800.00%, WMAPE: 108.09%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 150/500\n",
            "Train - RMSE: 1275.3868, MAE: 208.7538, R²: -0.0140, MAPE: 71805305600.00%, WMAPE: 101.10%\n",
            "Val   - RMSE: 1398.8705, MAE: 199.2507, R²: -0.0108, MAPE: 73436934400.00%, WMAPE: 101.33%\n",
            "Test  - RMSE: 866.7316, MAE: 99.3459, R²: -0.0006, MAPE: 99808051200.00%, WMAPE: 108.56%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 160/500\n",
            "Train - RMSE: 1274.8971, MAE: 208.8463, R²: -0.0132, MAPE: 75596595200.00%, WMAPE: 101.15%\n",
            "Val   - RMSE: 1398.4797, MAE: 199.3675, R²: -0.0102, MAPE: 77334604800.00%, WMAPE: 101.39%\n",
            "Test  - RMSE: 866.4619, MAE: 99.7674, R²: -0.0000, MAPE: 105252153600.00%, WMAPE: 109.02%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 170/500\n",
            "Train - RMSE: 1274.4080, MAE: 208.9335, R²: -0.0124, MAPE: 79317536000.00%, WMAPE: 101.19%\n",
            "Val   - RMSE: 1398.0905, MAE: 199.4795, R²: -0.0097, MAPE: 81164569600.00%, WMAPE: 101.45%\n",
            "Test  - RMSE: 866.1941, MAE: 100.1816, R²: 0.0006, MAPE: 110615936000.00%, WMAPE: 109.47%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 180/500\n",
            "Train - RMSE: 1273.9214, MAE: 209.0166, R²: -0.0116, MAPE: 82972620800.00%, WMAPE: 101.23%\n",
            "Val   - RMSE: 1397.7032, MAE: 199.5879, R²: -0.0091, MAPE: 84927276800.00%, WMAPE: 101.50%\n",
            "Test  - RMSE: 865.9291, MAE: 100.5888, R²: 0.0012, MAPE: 115897356800.00%, WMAPE: 109.92%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 190/500\n",
            "Train - RMSE: 1273.4384, MAE: 209.0976, R²: -0.0109, MAPE: 86574176000.00%, WMAPE: 101.27%\n",
            "Val   - RMSE: 1397.3184, MAE: 199.6943, R²: -0.0086, MAPE: 88636268800.00%, WMAPE: 101.56%\n",
            "Test  - RMSE: 865.6666, MAE: 100.9904, R²: 0.0018, MAPE: 121107456000.00%, WMAPE: 110.36%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 200/500\n",
            "Train - RMSE: 1272.9559, MAE: 209.1749, R²: -0.0101, MAPE: 90117779200.00%, WMAPE: 101.31%\n",
            "Val   - RMSE: 1396.9337, MAE: 199.7961, R²: -0.0080, MAPE: 92283782400.00%, WMAPE: 101.61%\n",
            "Test  - RMSE: 865.4055, MAE: 101.3856, R²: 0.0024, MAPE: 126245504000.00%, WMAPE: 110.79%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 210/500\n",
            "Train - RMSE: 1272.4774, MAE: 209.2494, R²: -0.0093, MAPE: 93611379200.00%, WMAPE: 101.34%\n",
            "Val   - RMSE: 1396.5522, MAE: 199.8963, R²: -0.0075, MAPE: 95887219200.00%, WMAPE: 101.66%\n",
            "Test  - RMSE: 865.1474, MAE: 101.7757, R²: 0.0030, MAPE: 131321830400.00%, WMAPE: 111.21%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 220/500\n",
            "Train - RMSE: 1271.9989, MAE: 209.3204, R²: -0.0086, MAPE: 97052083200.00%, WMAPE: 101.38%\n",
            "Val   - RMSE: 1396.1724, MAE: 199.9935, R²: -0.0069, MAPE: 99440096000.00%, WMAPE: 101.71%\n",
            "Test  - RMSE: 864.8915, MAE: 102.1610, R²: 0.0036, MAPE: 136338675200.00%, WMAPE: 111.64%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 230/500\n",
            "Train - RMSE: 1271.5225, MAE: 209.3884, R²: -0.0078, MAPE: 100435737600.00%, WMAPE: 101.41%\n",
            "Val   - RMSE: 1395.7938, MAE: 200.0873, R²: -0.0064, MAPE: 102935302400.00%, WMAPE: 101.76%\n",
            "Test  - RMSE: 864.6375, MAE: 102.5404, R²: 0.0042, MAPE: 141285030400.00%, WMAPE: 112.05%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 240/500\n",
            "Train - RMSE: 1271.0490, MAE: 209.4556, R²: -0.0071, MAPE: 103779289600.00%, WMAPE: 101.44%\n",
            "Val   - RMSE: 1395.4178, MAE: 200.1807, R²: -0.0058, MAPE: 106394086400.00%, WMAPE: 101.80%\n",
            "Test  - RMSE: 864.3865, MAE: 102.9163, R²: 0.0048, MAPE: 146181465600.00%, WMAPE: 112.46%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 250/500\n",
            "Train - RMSE: 1270.5781, MAE: 209.5210, R²: -0.0063, MAPE: 107076422400.00%, WMAPE: 101.47%\n",
            "Val   - RMSE: 1395.0444, MAE: 200.2720, R²: -0.0053, MAPE: 109803238400.00%, WMAPE: 101.85%\n",
            "Test  - RMSE: 864.1382, MAE: 103.2874, R²: 0.0053, MAPE: 151016652800.00%, WMAPE: 112.87%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 260/500\n",
            "Train - RMSE: 1270.1079, MAE: 209.5842, R²: -0.0056, MAPE: 110331200000.00%, WMAPE: 101.50%\n",
            "Val   - RMSE: 1394.6718, MAE: 200.3621, R²: -0.0047, MAPE: 113174284800.00%, WMAPE: 101.90%\n",
            "Test  - RMSE: 863.8913, MAE: 103.6547, R²: 0.0059, MAPE: 155803392000.00%, WMAPE: 113.27%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 270/500\n",
            "Train - RMSE: 1269.6417, MAE: 209.6468, R²: -0.0049, MAPE: 113546854400.00%, WMAPE: 101.53%\n",
            "Val   - RMSE: 1394.3024, MAE: 200.4512, R²: -0.0042, MAPE: 116504371200.00%, WMAPE: 101.94%\n",
            "Test  - RMSE: 863.6474, MAE: 104.0181, R²: 0.0065, MAPE: 160537075200.00%, WMAPE: 113.67%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 280/500\n",
            "Train - RMSE: 1269.1776, MAE: 209.7086, R²: -0.0041, MAPE: 116728665600.00%, WMAPE: 101.56%\n",
            "Val   - RMSE: 1393.9349, MAE: 200.5405, R²: -0.0037, MAPE: 119803609600.00%, WMAPE: 101.99%\n",
            "Test  - RMSE: 863.4061, MAE: 104.3786, R²: 0.0070, MAPE: 165227545600.00%, WMAPE: 114.06%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 290/500\n",
            "Train - RMSE: 1268.7157, MAE: 209.7686, R²: -0.0034, MAPE: 119862400000.00%, WMAPE: 101.59%\n",
            "Val   - RMSE: 1393.5695, MAE: 200.6285, R²: -0.0032, MAPE: 123057241600.00%, WMAPE: 102.03%\n",
            "Test  - RMSE: 863.1669, MAE: 104.7348, R²: 0.0076, MAPE: 169860633600.00%, WMAPE: 114.45%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 300/500\n",
            "Train - RMSE: 1268.2531, MAE: 209.8264, R²: -0.0027, MAPE: 122952960000.00%, WMAPE: 101.62%\n",
            "Val   - RMSE: 1393.2036, MAE: 200.7148, R²: -0.0026, MAPE: 126267392000.00%, WMAPE: 102.08%\n",
            "Test  - RMSE: 862.9285, MAE: 105.0869, R²: 0.0081, MAPE: 174442982400.00%, WMAPE: 114.83%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 310/500\n",
            "Train - RMSE: 1267.7932, MAE: 209.8843, R²: -0.0019, MAPE: 126015014400.00%, WMAPE: 101.65%\n",
            "Val   - RMSE: 1392.8406, MAE: 200.8015, R²: -0.0021, MAPE: 129448640000.00%, WMAPE: 102.12%\n",
            "Test  - RMSE: 862.6929, MAE: 105.4365, R²: 0.0087, MAPE: 178986316800.00%, WMAPE: 115.22%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 320/500\n",
            "Train - RMSE: 1267.3346, MAE: 209.9408, R²: -0.0012, MAPE: 129036185600.00%, WMAPE: 101.68%\n",
            "Val   - RMSE: 1392.4788, MAE: 200.8871, R²: -0.0016, MAPE: 132590630400.00%, WMAPE: 102.16%\n",
            "Test  - RMSE: 862.4589, MAE: 105.7821, R²: 0.0092, MAPE: 183480384000.00%, WMAPE: 115.59%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 330/500\n",
            "Train - RMSE: 1266.8781, MAE: 209.9964, R²: -0.0005, MAPE: 132023961600.00%, WMAPE: 101.70%\n",
            "Val   - RMSE: 1392.1183, MAE: 200.9719, R²: -0.0011, MAPE: 135699648000.00%, WMAPE: 102.21%\n",
            "Test  - RMSE: 862.2268, MAE: 106.1244, R²: 0.0097, MAPE: 187932864000.00%, WMAPE: 115.97%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 340/500\n",
            "Train - RMSE: 1266.4226, MAE: 210.0511, R²: 0.0002, MAPE: 134982464000.00%, WMAPE: 101.73%\n",
            "Val   - RMSE: 1391.7594, MAE: 201.0563, R²: -0.0005, MAPE: 138781337600.00%, WMAPE: 102.25%\n",
            "Test  - RMSE: 861.9965, MAE: 106.4641, R²: 0.0103, MAPE: 192348288000.00%, WMAPE: 116.34%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 350/500\n",
            "Train - RMSE: 1265.9684, MAE: 210.1034, R²: 0.0010, MAPE: 137894924800.00%, WMAPE: 101.76%\n",
            "Val   - RMSE: 1391.4009, MAE: 201.1372, R²: -0.0000, MAPE: 141812390400.00%, WMAPE: 102.29%\n",
            "Test  - RMSE: 861.7674, MAE: 106.7988, R²: 0.0108, MAPE: 196705792000.00%, WMAPE: 116.70%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 360/500\n",
            "Train - RMSE: 1265.5160, MAE: 210.1560, R²: 0.0017, MAPE: 140785779200.00%, WMAPE: 101.78%\n",
            "Val   - RMSE: 1391.0442, MAE: 201.2189, R²: 0.0005, MAPE: 144825459200.00%, WMAPE: 102.33%\n",
            "Test  - RMSE: 861.5405, MAE: 107.1319, R²: 0.0113, MAPE: 201035481600.00%, WMAPE: 117.07%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 370/500\n",
            "Train - RMSE: 1265.0667, MAE: 210.2089, R²: 0.0024, MAPE: 143655769600.00%, WMAPE: 101.81%\n",
            "Val   - RMSE: 1390.6902, MAE: 201.3007, R²: 0.0010, MAPE: 147816332800.00%, WMAPE: 102.37%\n",
            "Test  - RMSE: 861.3159, MAE: 107.4630, R²: 0.0118, MAPE: 205335424000.00%, WMAPE: 117.43%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 380/500\n",
            "Train - RMSE: 1264.6169, MAE: 210.2597, R²: 0.0031, MAPE: 146491174400.00%, WMAPE: 101.83%\n",
            "Val   - RMSE: 1390.3362, MAE: 201.3802, R²: 0.0015, MAPE: 150770150400.00%, WMAPE: 102.41%\n",
            "Test  - RMSE: 861.0924, MAE: 107.7904, R²: 0.0123, MAPE: 209593369600.00%, WMAPE: 117.79%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 390/500\n",
            "Train - RMSE: 1264.1697, MAE: 210.3104, R²: 0.0038, MAPE: 149311910400.00%, WMAPE: 101.86%\n",
            "Val   - RMSE: 1389.9841, MAE: 201.4594, R²: 0.0020, MAPE: 153708454400.00%, WMAPE: 102.45%\n",
            "Test  - RMSE: 860.8707, MAE: 108.1165, R²: 0.0129, MAPE: 213830860800.00%, WMAPE: 118.14%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 400/500\n",
            "Train - RMSE: 1263.7242, MAE: 210.3595, R²: 0.0045, MAPE: 152096537600.00%, WMAPE: 101.88%\n",
            "Val   - RMSE: 1389.6335, MAE: 201.5369, R²: 0.0025, MAPE: 156609804800.00%, WMAPE: 102.49%\n",
            "Test  - RMSE: 860.6511, MAE: 108.4389, R²: 0.0134, MAPE: 218022246400.00%, WMAPE: 118.50%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 410/500\n",
            "Train - RMSE: 1263.2795, MAE: 210.4064, R²: 0.0052, MAPE: 154841804800.00%, WMAPE: 101.90%\n",
            "Val   - RMSE: 1389.2838, MAE: 201.6126, R²: 0.0030, MAPE: 159475123200.00%, WMAPE: 102.53%\n",
            "Test  - RMSE: 860.4328, MAE: 108.7576, R²: 0.0139, MAPE: 222166988800.00%, WMAPE: 118.84%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 420/500\n",
            "Train - RMSE: 1262.8370, MAE: 210.4532, R²: 0.0059, MAPE: 157584972800.00%, WMAPE: 101.92%\n",
            "Val   - RMSE: 1388.9358, MAE: 201.6888, R²: 0.0035, MAPE: 162341030400.00%, WMAPE: 102.57%\n",
            "Test  - RMSE: 860.2162, MAE: 109.0762, R²: 0.0144, MAPE: 226309708800.00%, WMAPE: 119.19%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 430/500\n",
            "Train - RMSE: 1262.3951, MAE: 210.4978, R²: 0.0066, MAPE: 160288153600.00%, WMAPE: 101.95%\n",
            "Val   - RMSE: 1388.5886, MAE: 201.7621, R²: 0.0040, MAPE: 165164774400.00%, WMAPE: 102.61%\n",
            "Test  - RMSE: 860.0009, MAE: 109.3904, R²: 0.0148, MAPE: 230401766400.00%, WMAPE: 119.54%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 440/500\n",
            "Train - RMSE: 1261.9546, MAE: 210.5416, R²: 0.0073, MAPE: 162968000000.00%, WMAPE: 101.97%\n",
            "Val   - RMSE: 1388.2426, MAE: 201.8343, R²: 0.0045, MAPE: 167963417600.00%, WMAPE: 102.65%\n",
            "Test  - RMSE: 859.7872, MAE: 109.7020, R²: 0.0153, MAPE: 234461696000.00%, WMAPE: 119.88%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 450/500\n",
            "Train - RMSE: 1261.5157, MAE: 210.5855, R²: 0.0080, MAPE: 165632396800.00%, WMAPE: 101.99%\n",
            "Val   - RMSE: 1387.8982, MAE: 201.9069, R²: 0.0050, MAPE: 170747814400.00%, WMAPE: 102.68%\n",
            "Test  - RMSE: 859.5756, MAE: 110.0123, R²: 0.0158, MAPE: 238499430400.00%, WMAPE: 120.22%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 460/500\n",
            "Train - RMSE: 1261.0775, MAE: 210.6271, R²: 0.0087, MAPE: 168257267200.00%, WMAPE: 102.01%\n",
            "Val   - RMSE: 1387.5538, MAE: 201.9768, R²: 0.0055, MAPE: 173490777600.00%, WMAPE: 102.72%\n",
            "Test  - RMSE: 859.3647, MAE: 110.3182, R²: 0.0163, MAPE: 242487296000.00%, WMAPE: 120.55%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 470/500\n",
            "Train - RMSE: 1260.6405, MAE: 210.6680, R²: 0.0093, MAPE: 170865292800.00%, WMAPE: 102.03%\n",
            "Val   - RMSE: 1387.2115, MAE: 202.0471, R²: 0.0060, MAPE: 176222348800.00%, WMAPE: 102.75%\n",
            "Test  - RMSE: 859.1559, MAE: 110.6230, R²: 0.0168, MAPE: 246455065600.00%, WMAPE: 120.88%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 480/500\n",
            "Train - RMSE: 1260.2053, MAE: 210.7073, R²: 0.0100, MAPE: 173444659200.00%, WMAPE: 102.05%\n",
            "Val   - RMSE: 1386.8701, MAE: 202.1157, R²: 0.0065, MAPE: 178925913600.00%, WMAPE: 102.79%\n",
            "Test  - RMSE: 858.9484, MAE: 110.9248, R²: 0.0173, MAPE: 250388556800.00%, WMAPE: 121.21%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 490/500\n",
            "Train - RMSE: 1259.7720, MAE: 210.7474, R²: 0.0107, MAPE: 176016806400.00%, WMAPE: 102.07%\n",
            "Val   - RMSE: 1386.5308, MAE: 202.1856, R²: 0.0070, MAPE: 181625728000.00%, WMAPE: 102.82%\n",
            "Test  - RMSE: 858.7432, MAE: 111.2262, R²: 0.0177, MAPE: 254309580800.00%, WMAPE: 121.54%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 500/500\n",
            "Train - RMSE: 1259.3395, MAE: 210.7849, R²: 0.0114, MAPE: 178545472000.00%, WMAPE: 102.09%\n",
            "Val   - RMSE: 1386.1919, MAE: 202.2516, R²: 0.0074, MAPE: 184277222400.00%, WMAPE: 102.86%\n",
            "Test  - RMSE: 858.5388, MAE: 111.5225, R²: 0.0182, MAPE: 258175564800.00%, WMAPE: 121.87%\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate metrics for t=1 to t=5 and t=1 to t=13\n",
        "def calculate_final_metrics(y_true, y_pred, n_steps_list):\n",
        "    results = {}\n",
        "    for n in n_steps_list:\n",
        "        mse, rmse, mae, r2, mape_value, wmape_value = calculate_metrics(y_true, y_pred, n)\n",
        "        results[f'n={n}'] = {\n",
        "            'MSE': mse,\n",
        "            'RMSE': rmse,\n",
        "            'MAE': mae,\n",
        "            'R2': r2,\n",
        "            'MAPE': mape_value,\n",
        "            'WMAPE': wmape_value\n",
        "        }\n",
        "    return results\n",
        "\n",
        "# Evaluate on train set\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    y_pred_train = model(X_train)\n",
        "    train_results = calculate_final_metrics(y_train, y_pred_train, [5, 13])\n",
        "\n",
        "    y_pred_val = model(X_val)\n",
        "    val_results = calculate_final_metrics(y_val, y_pred_val, [5, 13])\n",
        "\n",
        "    y_pred_test = model(X_test)\n",
        "    test_results = calculate_final_metrics(y_test, y_pred_test, [5, 13])\n",
        "\n",
        "# Print final metrics\n",
        "def print_results(results, dataset_name):\n",
        "    print(f\"\\n{dataset_name} Metrics:\")\n",
        "    for n, metrics in results.items():\n",
        "        print(f\"\\nFrom t=1 to t={n.split('=')[1]}:\")\n",
        "        print(f\"MSE: {metrics['MSE']:.4f}\")\n",
        "        print(f\"RMSE: {metrics['RMSE']:.4f}\")\n",
        "        print(f\"MAE: {metrics['MAE']:.4f}\")\n",
        "        print(f\"R²: {metrics['R2']:.4f}\")\n",
        "        print(f\"MAPE: {metrics['MAPE']:.2f}%\")\n",
        "        print(f\"WMAPE: {metrics['WMAPE']:.2f}%\")\n",
        "\n",
        "print_results(train_results, \"Train\")\n",
        "print_results(val_results, \"Validation\")\n",
        "print_results(test_results, \"Test\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_VHQ0S_sFK8",
        "outputId": "0d45aa2e-34bd-481e-f77e-2d85608f1938"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train Metrics:\n",
            "\n",
            "From t=1 to t=5:\n",
            "MSE: 1583241.2500\n",
            "RMSE: 1258.2692\n",
            "MAE: 210.8065\n",
            "R²: 0.0114\n",
            "MAPE: 179570124800.00%\n",
            "WMAPE: 102.17%\n",
            "\n",
            "From t=1 to t=13:\n",
            "MSE: 1585936.0000\n",
            "RMSE: 1259.3395\n",
            "MAE: 210.7849\n",
            "R²: 0.0114\n",
            "MAPE: 178545472000.00%\n",
            "WMAPE: 102.09%\n",
            "\n",
            "Validation Metrics:\n",
            "\n",
            "From t=1 to t=5:\n",
            "MSE: 1867829.0000\n",
            "RMSE: 1366.6854\n",
            "MAE: 203.5382\n",
            "R²: 0.0078\n",
            "MAPE: 182648678400.00%\n",
            "WMAPE: 102.64%\n",
            "\n",
            "From t=1 to t=13:\n",
            "MSE: 1921527.8750\n",
            "RMSE: 1386.1919\n",
            "MAE: 202.2516\n",
            "R²: 0.0074\n",
            "MAPE: 184277222400.00%\n",
            "WMAPE: 102.86%\n",
            "\n",
            "Test Metrics:\n",
            "\n",
            "From t=1 to t=5:\n",
            "MSE: 795242.4375\n",
            "RMSE: 891.7637\n",
            "MAE: 110.4195\n",
            "R²: 0.0161\n",
            "MAPE: 259224140800.00%\n",
            "WMAPE: 122.34%\n",
            "\n",
            "From t=1 to t=13:\n",
            "MSE: 737088.8125\n",
            "RMSE: 858.5388\n",
            "MAE: 111.5225\n",
            "R²: 0.0182\n",
            "MAPE: 258175564800.00%\n",
            "WMAPE: 121.87%\n"
          ]
        }
      ]
    }
  ]
}