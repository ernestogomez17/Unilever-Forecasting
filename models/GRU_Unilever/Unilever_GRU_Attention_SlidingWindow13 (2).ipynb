{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "e8r5EgJur6M3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from torch.utils.data import DataLoader, TensorDataset, Subset\n",
        "import sklearn.metrics as sk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1ATXQJXr_xt",
        "outputId": "6f0798f2-73fc-4643-c4e1-c74a4e8d02f6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.load(\"/content/drive/MyDrive/Unilever Datasets, Sliding Window 13/HEALTHY SNACKING_dataset_processed (1).npz\")"
      ],
      "metadata": {
        "id": "tbmLmJXGsC1G"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Extract the arrays\n",
        "X = data['X']  # Shape: (timesteps, input_sequence_length, nodes, features)\n",
        "Y = data['Y']  # Shape: (timesteps, output_sequence_length, nodes, features)\n",
        "\n",
        "# Drop all features except the first one for both X and Y\n",
        "X = X[:, :, :, :1]  # Keep only the first feature\n",
        "Y = Y[:, :, :, :1]  # Keep only the first feature\n"
      ],
      "metadata": {
        "id": "jpxlOZ5psE45"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape Y to match the output format, if necessary\n",
        "# Y is expected to have shape (timestep/index, prediction window, nodes, 1)\n",
        "# If Y's shape is already correct, skip this step\n",
        "X = X.squeeze(-1)\n",
        "Y = Y.squeeze(-1)  # Remove the last dimension"
      ],
      "metadata": {
        "id": "lBI1WwzfLJOH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Y shape after squeezing:\", Y.shape)\n",
        "print(\"Y sample:\", Y[:5])  # Print a small portion of Y to verify\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmGCSZPSSkev",
        "outputId": "56fbeafc-7c11-43ca-db29-d3ae5ba4de6b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Y shape after squeezing: (167, 13, 1082)\n",
            "Y sample: [[[360. 360.   0. ...   0.   0.   0.]\n",
            "  [360. 360.   2. ...   0.   0.   0.]\n",
            "  [120. 120.   0. ...   0.   0.   0.]\n",
            "  ...\n",
            "  [  0. 240.   0. ...   0.   0.   0.]\n",
            "  [  0.   0.   0. ...   0.   0.   0.]\n",
            "  [  0.   0.   0. ...   0.   0.   0.]]\n",
            "\n",
            " [[360. 360.   2. ...   0.   0.   0.]\n",
            "  [120. 120.   0. ...   0.   0.   0.]\n",
            "  [  0. 480.   0. ...   0.   0.   0.]\n",
            "  ...\n",
            "  [  0.   0.   0. ...   0.   0.   0.]\n",
            "  [  0.   0.   0. ...   0.   0.   0.]\n",
            "  [  0.   0.   0. ...   0.   0.   0.]]\n",
            "\n",
            " [[120. 120.   0. ...   0.   0.   0.]\n",
            "  [  0. 480.   0. ...   0.   0.   0.]\n",
            "  [360.   0.   0. ...   0.   0.   0.]\n",
            "  ...\n",
            "  [  0.   0.   0. ...   0.   0.   0.]\n",
            "  [  0.   0.   0. ...   0.   0.   0.]\n",
            "  [  0.   0.   0. ...   0.   0.   0.]]\n",
            "\n",
            " [[  0. 480.   0. ...   0.   0.   0.]\n",
            "  [360.   0.   0. ...   0.   0.   0.]\n",
            "  [  0. 600.   0. ...   0.   0.   0.]\n",
            "  ...\n",
            "  [  0.   0.   0. ...   0.   0.   0.]\n",
            "  [  0.   0.   0. ...   0.   0.   0.]\n",
            "  [  0.   0.   3. ...   0.   0.   0.]]\n",
            "\n",
            " [[360.   0.   0. ...   0.   0.   0.]\n",
            "  [  0. 600.   0. ...   0.   0.   0.]\n",
            "  [360. 480.   0. ...   0.   0.   0.]\n",
            "  ...\n",
            "  [  0.   0.   0. ...   0.   0.   0.]\n",
            "  [  0.   0.   3. ...   0.   0.   0.]\n",
            "  [  0.   0.   0. ...   0.   0.   0.]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify that the input and output sequence lengths are 13\n",
        "assert X.shape[1] == 13, f\"Expected input sequence length of 13, got {X.shape[1]}\"\n",
        "assert Y.shape[1] == 13, f\"Expected output sequence length of 13, got {Y.shape[1]}\"\n",
        "\n",
        "# Split the data into train, validation, and test sets (70%, 15%, 15%)\n",
        "train_size = int(len(X) * 0.7)\n",
        "val_size = int(len(X) * 0.15)\n",
        "test_size = len(X) - train_size - val_size\n",
        "\n",
        "X_train, X_val, X_test = X[:train_size], X[train_size:train_size + val_size], X[train_size + val_size:]\n",
        "y_train, y_val, y_test = Y[:train_size], Y[train_size:train_size + val_size], Y[train_size + val_size:]\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
        "X_val = torch.tensor(X_val, dtype=torch.float32)\n",
        "y_val = torch.tensor(y_val, dtype=torch.float32)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test = torch.tensor(y_test, dtype=torch.float32)\n",
        "\n",
        "# Print shapes to verify\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"X_val shape:\", X_val.shape)\n",
        "print(\"y_val shape:\", y_val.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_test shape:\", y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shNXGNyDISAt",
        "outputId": "1841fa71-ab8f-4d3b-d42f-ea72152e296e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: torch.Size([116, 13, 1082])\n",
            "y_train shape: torch.Size([116, 13, 1082])\n",
            "X_val shape: torch.Size([25, 13, 1082])\n",
            "y_val shape: torch.Size([25, 13, 1082])\n",
            "X_test shape: torch.Size([26, 13, 1082])\n",
            "y_test shape: torch.Size([26, 13, 1082])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the GRU model with Attention\n",
        "class AirModelWithAttention(nn.Module):\n",
        "    def __init__(self, input_sz, hidden_sz, output_sz, n_steps, dropout_prob=0.1):\n",
        "        super().__init__()\n",
        "        self.hidden_sz = hidden_sz\n",
        "        self.gru = nn.GRU(\n",
        "            input_size=input_sz,\n",
        "            hidden_size=hidden_sz,\n",
        "            num_layers=2,\n",
        "            batch_first=True,\n",
        "            bidirectional=False\n",
        "        )\n",
        "        self.dropout = nn.Dropout(p=dropout_prob)\n",
        "\n",
        "        # Attention layer\n",
        "        self.attention = nn.Linear(hidden_sz, 1)\n",
        "\n",
        "        # Output layer\n",
        "        self.linear = nn.Linear(hidden_sz, output_sz * n_steps)\n",
        "        self.output_sz = output_sz\n",
        "        self.n_steps = n_steps\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [batch_size, seq_length, input_size]\n",
        "        gru_output, _ = self.gru(x)  # gru_output: [batch_size, seq_length, hidden_sz]\n",
        "\n",
        "        # Apply attention\n",
        "        # Compute attention scores\n",
        "        attn_scores = self.attention(gru_output)  # attn_scores: [batch_size, seq_length, 1]\n",
        "        attn_scores = attn_scores.squeeze(-1)     # attn_scores: [batch_size, seq_length]\n",
        "\n",
        "        # Normalize attention scores to get attention weights\n",
        "        attn_weights = torch.softmax(attn_scores, dim=1)  # attn_weights: [batch_size, seq_length]\n",
        "\n",
        "        # Compute context vector as weighted sum of GRU outputs\n",
        "        context_vector = torch.sum(gru_output * attn_weights.unsqueeze(-1), dim=1)  # context_vector: [batch_size, hidden_sz]\n",
        "\n",
        "        # Apply dropout\n",
        "        context_vector = self.dropout(context_vector)\n",
        "\n",
        "        # Pass context vector through the output layer\n",
        "        output = self.linear(context_vector)\n",
        "        output = torch.relu(output)\n",
        "\n",
        "        # Reshape output to match the desired format\n",
        "        output = output.view(-1, self.n_steps, self.output_sz)\n",
        "        return output\n"
      ],
      "metadata": {
        "id": "BkYlFcIssFEy"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model parameters\n",
        "input_size = X_train.shape[2]\n",
        "output_size = y_train.shape[2]\n",
        "model = AirModelWithAttention(\n",
        "    input_sz=input_size,\n",
        "    hidden_sz=50,\n",
        "    output_sz=output_size,\n",
        "    n_steps=13,  # Updated to match the forecasting window\n",
        "    dropout_prob=0.1  # Added dropout for regularization\n",
        ")\n",
        "\n",
        "# Optimizer and loss function\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Reduced learning rate for stability\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "# Prepare the data loader\n",
        "train_data = TensorDataset(X_train, y_train)\n",
        "train_loader = DataLoader(train_data, batch_size=16, shuffle=False)\n",
        "\n",
        "# Lists to store metrics\n",
        "train_metrics = {'RMSE': [], 'MAE': [], 'R2': [], 'MSE': [], 'MAPE': [], 'WMAPE': []}\n",
        "val_metrics = {'RMSE': [], 'MAE': [], 'R2': [], 'MSE': [], 'MAPE': [], 'WMAPE': []}\n",
        "test_metrics = {'RMSE': [], 'MAE': [], 'R2': [], 'MSE': [], 'MAPE': [], 'WMAPE': []}\n",
        "\n",
        "# Function to calculate WMAPE\n",
        "def wmape(y_true, y_pred):\n",
        "    y_true = y_true.flatten()\n",
        "    y_pred = y_pred.flatten()\n",
        "    return np.sum(np.abs(y_true - y_pred)) / np.sum(np.abs(y_true))\n",
        "\n",
        "# Function to calculate MAPE\n",
        "def mape(y_true, y_pred):\n",
        "    y_true = y_true.flatten()\n",
        "    y_pred = y_pred.flatten()\n",
        "    # Create a mask for non-zero actuals\n",
        "    mask = y_true != 0\n",
        "    # Ensure there are non-zero actuals to prevent division by zero in the mean\n",
        "    if np.sum(mask) == 0:\n",
        "        return np.nan  # Or handle appropriately\n",
        "    # Compute MAPE only on non-zero actuals\n",
        "    return np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100\n",
        "\n",
        "\n",
        "# This is a function to calculate mape that assumes there are no 0 y_actuals\n",
        "# def mape(y_true, y_pred):\n",
        "#     y_true = y_true.flatten()\n",
        "#     y_pred = y_pred.flatten()\n",
        "#     return np.mean(np.abs((y_true - y_pred) / (y_true + 1e-8))) * 100  # Added 1e-8 to avoid division by zero\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Training loop\n",
        "n_epochs = 500\n",
        "for epoch in range(n_epochs):\n",
        "    model.train()\n",
        "    for X_batch, y_batch in train_loader:\n",
        "        y_pred = model(X_batch)\n",
        "        loss = loss_fn(y_pred, y_batch)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    # Validation every epoch\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # Helper function to calculate metrics\n",
        "        def calculate_metrics(y_true, y_pred, n):\n",
        "            y_true = y_true[:, :n, :].cpu().numpy()\n",
        "            y_pred = y_pred[:, :n, :].cpu().numpy()\n",
        "\n",
        "            mse = mean_squared_error(y_true.flatten(), y_pred.flatten())\n",
        "            rmse = np.sqrt(mse)\n",
        "            mae = mean_absolute_error(y_true.flatten(), y_pred.flatten())\n",
        "            r2 = r2_score(y_true.flatten(), y_pred.flatten())\n",
        "            mape_value = mape(y_true, y_pred)\n",
        "            wmape_value = wmape(y_true, y_pred) * 100\n",
        "            return mse, rmse, mae, r2, mape_value, wmape_value\n",
        "\n",
        "        # Training metrics\n",
        "        y_pred_train = model(X_train)\n",
        "        mse_train, rmse_train, mae_train, r2_train, mape_train, wmape_train = calculate_metrics(y_train, y_pred_train, 13)\n",
        "        train_metrics['MSE'].append(mse_train)\n",
        "        train_metrics['RMSE'].append(rmse_train)\n",
        "        train_metrics['MAE'].append(mae_train)\n",
        "        train_metrics['R2'].append(r2_train)\n",
        "        train_metrics['MAPE'].append(mape_train)\n",
        "        train_metrics['WMAPE'].append(wmape_train)\n",
        "\n",
        "        # Validation metrics\n",
        "        y_pred_val = model(X_val)\n",
        "        mse_val, rmse_val, mae_val, r2_val, mape_val, wmape_val = calculate_metrics(y_val, y_pred_val, 13)\n",
        "        val_metrics['MSE'].append(mse_val)\n",
        "        val_metrics['RMSE'].append(rmse_val)\n",
        "        val_metrics['MAE'].append(mae_val)\n",
        "        val_metrics['R2'].append(r2_val)\n",
        "        val_metrics['MAPE'].append(mape_val)\n",
        "        val_metrics['WMAPE'].append(wmape_val)\n",
        "\n",
        "        # Testing metrics\n",
        "        y_pred_test = model(X_test)\n",
        "        mse_test, rmse_test, mae_test, r2_test, mape_test, wmape_test = calculate_metrics(y_test, y_pred_test, 13)\n",
        "        test_metrics['MSE'].append(mse_test)\n",
        "        test_metrics['RMSE'].append(rmse_test)\n",
        "        test_metrics['MAE'].append(mae_test)\n",
        "        test_metrics['R2'].append(r2_test)\n",
        "        test_metrics['MAPE'].append(mape_test)\n",
        "        test_metrics['WMAPE'].append(wmape_test)\n",
        "\n",
        "    # Print metrics every 10 epochs\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f\"Epoch {epoch+1}/{n_epochs}\")\n",
        "        print(f\"Train - RMSE: {rmse_train:.4f}, MAE: {mae_train:.4f}, R²: {r2_train:.4f}, MAPE: {mape_train:.2f}%, WMAPE: {wmape_train:.2f}%\")\n",
        "        print(f\"Val   - RMSE: {rmse_val:.4f}, MAE: {mae_val:.4f}, R²: {r2_val:.4f}, MAPE: {mape_val:.2f}%, WMAPE: {wmape_val:.2f}%\")\n",
        "        print(f\"Test  - RMSE: {rmse_test:.4f}, MAE: {mae_test:.4f}, R²: {r2_test:.4f}, MAPE: {mape_test:.2f}%, WMAPE: {wmape_test:.2f}%\")\n",
        "        print(\"-\" * 80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SewJF72sFHY",
        "outputId": "03653ba4-bc49-4f1d-d961-d14d65165433"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/500\n",
            "Train - RMSE: 1282.7150, MAE: 206.7544, R²: -0.0257, MAPE: 96.88%, WMAPE: 100.13%\n",
            "Val   - RMSE: 1404.7386, MAE: 196.9454, R²: -0.0193, MAPE: 97.73%, WMAPE: 100.16%\n",
            "Test  - RMSE: 870.9313, MAE: 92.2037, R²: -0.0104, MAPE: 97.96%, WMAPE: 100.76%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 20/500\n",
            "Train - RMSE: 1282.1305, MAE: 206.9660, R²: -0.0247, MAPE: 95.95%, WMAPE: 100.24%\n",
            "Val   - RMSE: 1404.2682, MAE: 197.1809, R²: -0.0186, MAPE: 96.70%, WMAPE: 100.28%\n",
            "Test  - RMSE: 870.5827, MAE: 92.8499, R²: -0.0095, MAPE: 96.79%, WMAPE: 101.46%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 30/500\n",
            "Train - RMSE: 1281.5723, MAE: 207.1482, R²: -0.0238, MAPE: 95.39%, WMAPE: 100.32%\n",
            "Val   - RMSE: 1403.8208, MAE: 197.3834, R²: -0.0180, MAPE: 96.01%, WMAPE: 100.38%\n",
            "Test  - RMSE: 870.2538, MAE: 93.4279, R²: -0.0088, MAPE: 96.00%, WMAPE: 102.09%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 40/500\n",
            "Train - RMSE: 1281.0309, MAE: 207.3142, R²: -0.0230, MAPE: 95.04%, WMAPE: 100.40%\n",
            "Val   - RMSE: 1403.3866, MAE: 197.5681, R²: -0.0173, MAPE: 95.50%, WMAPE: 100.48%\n",
            "Test  - RMSE: 869.9368, MAE: 93.9752, R²: -0.0080, MAPE: 95.43%, WMAPE: 102.69%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 50/500\n",
            "Train - RMSE: 1280.4978, MAE: 207.4686, R²: -0.0221, MAPE: 94.79%, WMAPE: 100.48%\n",
            "Val   - RMSE: 1402.9596, MAE: 197.7401, R²: -0.0167, MAPE: 95.12%, WMAPE: 100.56%\n",
            "Test  - RMSE: 869.6263, MAE: 94.4994, R²: -0.0073, MAPE: 95.08%, WMAPE: 103.26%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 60/500\n",
            "Train - RMSE: 1279.9714, MAE: 207.6125, R²: -0.0213, MAPE: 94.59%, WMAPE: 100.55%\n",
            "Val   - RMSE: 1402.5389, MAE: 197.9024, R²: -0.0161, MAPE: 94.82%, WMAPE: 100.65%\n",
            "Test  - RMSE: 869.3222, MAE: 95.0034, R²: -0.0066, MAPE: 94.83%, WMAPE: 103.81%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 70/500\n",
            "Train - RMSE: 1279.4485, MAE: 207.7471, R²: -0.0204, MAPE: 94.41%, WMAPE: 100.61%\n",
            "Val   - RMSE: 1402.1215, MAE: 198.0550, R²: -0.0155, MAPE: 94.58%, WMAPE: 100.72%\n",
            "Test  - RMSE: 869.0214, MAE: 95.4916, R²: -0.0059, MAPE: 94.62%, WMAPE: 104.35%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 80/500\n",
            "Train - RMSE: 1278.9307, MAE: 207.8748, R²: -0.0196, MAPE: 94.24%, WMAPE: 100.68%\n",
            "Val   - RMSE: 1401.7081, MAE: 198.2009, R²: -0.0149, MAPE: 94.38%, WMAPE: 100.80%\n",
            "Test  - RMSE: 868.7248, MAE: 95.9676, R²: -0.0052, MAPE: 94.45%, WMAPE: 104.87%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 90/500\n",
            "Train - RMSE: 1278.4185, MAE: 207.9968, R²: -0.0188, MAPE: 94.08%, WMAPE: 100.73%\n",
            "Val   - RMSE: 1401.2996, MAE: 198.3419, R²: -0.0143, MAPE: 94.21%, WMAPE: 100.87%\n",
            "Test  - RMSE: 868.4330, MAE: 96.4334, R²: -0.0046, MAPE: 94.31%, WMAPE: 105.38%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 100/500\n",
            "Train - RMSE: 1277.9106, MAE: 208.1115, R²: -0.0180, MAPE: 93.91%, WMAPE: 100.79%\n",
            "Val   - RMSE: 1400.8940, MAE: 198.4758, R²: -0.0137, MAPE: 94.05%, WMAPE: 100.94%\n",
            "Test  - RMSE: 868.1450, MAE: 96.8889, R²: -0.0039, MAPE: 94.20%, WMAPE: 105.87%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 110/500\n",
            "Train - RMSE: 1277.4033, MAE: 208.2196, R²: -0.0172, MAPE: 93.73%, WMAPE: 100.84%\n",
            "Val   - RMSE: 1400.4900, MAE: 198.6045, R²: -0.0131, MAPE: 93.90%, WMAPE: 101.00%\n",
            "Test  - RMSE: 867.8591, MAE: 97.3361, R²: -0.0032, MAPE: 94.10%, WMAPE: 106.36%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 120/500\n",
            "Train - RMSE: 1276.8975, MAE: 208.3225, R²: -0.0164, MAPE: 93.54%, WMAPE: 100.89%\n",
            "Val   - RMSE: 1400.0879, MAE: 198.7288, R²: -0.0126, MAPE: 93.77%, WMAPE: 101.07%\n",
            "Test  - RMSE: 867.5753, MAE: 97.7751, R²: -0.0026, MAPE: 94.02%, WMAPE: 106.84%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 130/500\n",
            "Train - RMSE: 1276.3958, MAE: 208.4214, R²: -0.0156, MAPE: 93.35%, WMAPE: 100.94%\n",
            "Val   - RMSE: 1399.6890, MAE: 198.8486, R²: -0.0120, MAPE: 93.62%, WMAPE: 101.13%\n",
            "Test  - RMSE: 867.2950, MAE: 98.2062, R²: -0.0019, MAPE: 93.94%, WMAPE: 107.31%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 140/500\n",
            "Train - RMSE: 1275.8978, MAE: 208.5161, R²: -0.0148, MAPE: 93.16%, WMAPE: 100.99%\n",
            "Val   - RMSE: 1399.2932, MAE: 198.9651, R²: -0.0114, MAPE: 93.50%, WMAPE: 101.19%\n",
            "Test  - RMSE: 867.0183, MAE: 98.6299, R²: -0.0013, MAPE: 93.87%, WMAPE: 107.78%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 150/500\n",
            "Train - RMSE: 1275.3994, MAE: 208.6069, R²: -0.0140, MAPE: 92.97%, WMAPE: 101.03%\n",
            "Val   - RMSE: 1398.8973, MAE: 199.0779, R²: -0.0108, MAPE: 93.37%, WMAPE: 101.24%\n",
            "Test  - RMSE: 866.7430, MAE: 99.0482, R²: -0.0007, MAPE: 93.81%, WMAPE: 108.23%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 160/500\n",
            "Train - RMSE: 1274.9049, MAE: 208.6949, R²: -0.0132, MAPE: 92.77%, WMAPE: 101.07%\n",
            "Val   - RMSE: 1398.5061, MAE: 199.1898, R²: -0.0103, MAPE: 93.23%, WMAPE: 101.30%\n",
            "Test  - RMSE: 866.4717, MAE: 99.4620, R²: -0.0000, MAPE: 93.75%, WMAPE: 108.69%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 170/500\n",
            "Train - RMSE: 1274.4136, MAE: 208.7780, R²: -0.0124, MAPE: 92.57%, WMAPE: 101.11%\n",
            "Val   - RMSE: 1398.1171, MAE: 199.2960, R²: -0.0097, MAPE: 93.10%, WMAPE: 101.35%\n",
            "Test  - RMSE: 866.2033, MAE: 99.8667, R²: 0.0006, MAPE: 93.69%, WMAPE: 109.13%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 180/500\n",
            "Train - RMSE: 1273.9237, MAE: 208.8571, R²: -0.0116, MAPE: 92.37%, WMAPE: 101.15%\n",
            "Val   - RMSE: 1397.7296, MAE: 199.3991, R²: -0.0092, MAPE: 92.97%, WMAPE: 101.41%\n",
            "Test  - RMSE: 865.9370, MAE: 100.2651, R²: 0.0012, MAPE: 93.63%, WMAPE: 109.56%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 190/500\n",
            "Train - RMSE: 1273.4368, MAE: 208.9324, R²: -0.0109, MAPE: 92.17%, WMAPE: 101.19%\n",
            "Val   - RMSE: 1397.3442, MAE: 199.4986, R²: -0.0086, MAPE: 92.84%, WMAPE: 101.46%\n",
            "Test  - RMSE: 865.6735, MAE: 100.6579, R²: 0.0018, MAPE: 93.56%, WMAPE: 109.99%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 200/500\n",
            "Train - RMSE: 1272.9518, MAE: 209.0049, R²: -0.0101, MAPE: 91.96%, WMAPE: 101.22%\n",
            "Val   - RMSE: 1396.9612, MAE: 199.5950, R²: -0.0080, MAPE: 92.71%, WMAPE: 101.51%\n",
            "Test  - RMSE: 865.4124, MAE: 101.0448, R²: 0.0024, MAPE: 93.50%, WMAPE: 110.42%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 210/500\n",
            "Train - RMSE: 1272.4700, MAE: 209.0744, R²: -0.0093, MAPE: 91.76%, WMAPE: 101.26%\n",
            "Val   - RMSE: 1396.5804, MAE: 199.6886, R²: -0.0075, MAPE: 92.57%, WMAPE: 101.55%\n",
            "Test  - RMSE: 865.1542, MAE: 101.4261, R²: 0.0030, MAPE: 93.43%, WMAPE: 110.83%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 220/500\n",
            "Train - RMSE: 1271.9904, MAE: 209.1418, R²: -0.0086, MAPE: 91.56%, WMAPE: 101.29%\n",
            "Val   - RMSE: 1396.2020, MAE: 199.7810, R²: -0.0069, MAPE: 92.44%, WMAPE: 101.60%\n",
            "Test  - RMSE: 864.8986, MAE: 101.8030, R²: 0.0036, MAPE: 93.37%, WMAPE: 111.24%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 230/500\n",
            "Train - RMSE: 1271.5120, MAE: 209.2068, R²: -0.0078, MAPE: 91.37%, WMAPE: 101.32%\n",
            "Val   - RMSE: 1395.8247, MAE: 199.8706, R²: -0.0064, MAPE: 92.32%, WMAPE: 101.65%\n",
            "Test  - RMSE: 864.6447, MAE: 102.1752, R²: 0.0042, MAPE: 93.32%, WMAPE: 111.65%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 240/500\n",
            "Train - RMSE: 1271.0321, MAE: 209.2694, R²: -0.0071, MAPE: 91.17%, WMAPE: 101.35%\n",
            "Val   - RMSE: 1395.4470, MAE: 199.9588, R²: -0.0059, MAPE: 92.19%, WMAPE: 101.69%\n",
            "Test  - RMSE: 864.3912, MAE: 102.5443, R²: 0.0048, MAPE: 93.27%, WMAPE: 112.05%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 250/500\n",
            "Train - RMSE: 1270.5560, MAE: 209.3310, R²: -0.0063, MAPE: 90.99%, WMAPE: 101.38%\n",
            "Val   - RMSE: 1395.0723, MAE: 200.0465, R²: -0.0053, MAPE: 92.07%, WMAPE: 101.74%\n",
            "Test  - RMSE: 864.1410, MAE: 102.9095, R²: 0.0053, MAPE: 93.22%, WMAPE: 112.45%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 260/500\n",
            "Train - RMSE: 1270.0804, MAE: 209.3903, R²: -0.0055, MAPE: 90.81%, WMAPE: 101.41%\n",
            "Val   - RMSE: 1394.6982, MAE: 200.1318, R²: -0.0048, MAPE: 91.97%, WMAPE: 101.78%\n",
            "Test  - RMSE: 863.8925, MAE: 103.2705, R²: 0.0059, MAPE: 93.19%, WMAPE: 112.85%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 270/500\n",
            "Train - RMSE: 1269.6078, MAE: 209.4489, R²: -0.0048, MAPE: 90.63%, WMAPE: 101.44%\n",
            "Val   - RMSE: 1394.3269, MAE: 200.2162, R²: -0.0042, MAPE: 91.86%, WMAPE: 101.82%\n",
            "Test  - RMSE: 863.6465, MAE: 103.6284, R²: 0.0065, MAPE: 93.15%, WMAPE: 113.24%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 280/500\n",
            "Train - RMSE: 1269.1375, MAE: 209.5052, R²: -0.0041, MAPE: 90.45%, WMAPE: 101.47%\n",
            "Val   - RMSE: 1393.9570, MAE: 200.2983, R²: -0.0037, MAPE: 91.76%, WMAPE: 101.86%\n",
            "Test  - RMSE: 863.4027, MAE: 103.9818, R²: 0.0070, MAPE: 93.12%, WMAPE: 113.63%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 290/500\n",
            "Train - RMSE: 1268.6675, MAE: 209.5596, R²: -0.0033, MAPE: 90.29%, WMAPE: 101.49%\n",
            "Val   - RMSE: 1393.5881, MAE: 200.3786, R²: -0.0032, MAPE: 91.67%, WMAPE: 101.90%\n",
            "Test  - RMSE: 863.1603, MAE: 104.3303, R²: 0.0076, MAPE: 93.09%, WMAPE: 114.01%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 300/500\n",
            "Train - RMSE: 1268.2002, MAE: 209.6136, R²: -0.0026, MAPE: 90.13%, WMAPE: 101.52%\n",
            "Val   - RMSE: 1393.2206, MAE: 200.4594, R²: -0.0027, MAPE: 91.59%, WMAPE: 101.95%\n",
            "Test  - RMSE: 862.9191, MAE: 104.6763, R²: 0.0081, MAPE: 93.07%, WMAPE: 114.38%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 310/500\n",
            "Train - RMSE: 1267.7332, MAE: 209.6666, R²: -0.0018, MAPE: 89.98%, WMAPE: 101.54%\n",
            "Val   - RMSE: 1392.8535, MAE: 200.5396, R²: -0.0021, MAPE: 91.50%, WMAPE: 101.99%\n",
            "Test  - RMSE: 862.6783, MAE: 105.0192, R²: 0.0087, MAPE: 93.04%, WMAPE: 114.76%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 320/500\n",
            "Train - RMSE: 1267.2693, MAE: 209.7188, R²: -0.0011, MAPE: 89.85%, WMAPE: 101.57%\n",
            "Val   - RMSE: 1392.4891, MAE: 200.6196, R²: -0.0016, MAPE: 91.44%, WMAPE: 102.03%\n",
            "Test  - RMSE: 862.4406, MAE: 105.3585, R²: 0.0092, MAPE: 93.03%, WMAPE: 115.13%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 330/500\n",
            "Train - RMSE: 1266.8054, MAE: 209.7691, R²: -0.0004, MAPE: 89.71%, WMAPE: 101.59%\n",
            "Val   - RMSE: 1392.1252, MAE: 200.6970, R²: -0.0011, MAPE: 91.38%, WMAPE: 102.07%\n",
            "Test  - RMSE: 862.2043, MAE: 105.6930, R²: 0.0098, MAPE: 93.02%, WMAPE: 115.50%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 340/500\n",
            "Train - RMSE: 1266.3440, MAE: 209.8197, R²: 0.0004, MAPE: 89.58%, WMAPE: 101.62%\n",
            "Val   - RMSE: 1391.7635, MAE: 200.7758, R²: -0.0006, MAPE: 91.32%, WMAPE: 102.11%\n",
            "Test  - RMSE: 861.9706, MAE: 106.0264, R²: 0.0103, MAPE: 93.01%, WMAPE: 115.86%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 350/500\n",
            "Train - RMSE: 1265.8857, MAE: 209.8698, R²: 0.0011, MAPE: 89.47%, WMAPE: 101.64%\n",
            "Val   - RMSE: 1391.4044, MAE: 200.8536, R²: -0.0000, MAPE: 91.26%, WMAPE: 102.15%\n",
            "Test  - RMSE: 861.7397, MAE: 106.3566, R²: 0.0109, MAPE: 93.01%, WMAPE: 116.22%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 360/500\n",
            "Train - RMSE: 1265.4282, MAE: 209.9184, R²: 0.0018, MAPE: 89.35%, WMAPE: 101.67%\n",
            "Val   - RMSE: 1391.0459, MAE: 200.9302, R²: 0.0005, MAPE: 91.22%, WMAPE: 102.19%\n",
            "Test  - RMSE: 861.5099, MAE: 106.6837, R²: 0.0114, MAPE: 93.00%, WMAPE: 116.58%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 370/500\n",
            "Train - RMSE: 1264.9725, MAE: 209.9663, R²: 0.0025, MAPE: 89.24%, WMAPE: 101.69%\n",
            "Val   - RMSE: 1390.6890, MAE: 201.0054, R²: 0.0010, MAPE: 91.17%, WMAPE: 102.22%\n",
            "Test  - RMSE: 861.2823, MAE: 107.0076, R²: 0.0119, MAPE: 93.00%, WMAPE: 116.93%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 380/500\n",
            "Train - RMSE: 1264.5171, MAE: 210.0130, R²: 0.0032, MAPE: 89.14%, WMAPE: 101.71%\n",
            "Val   - RMSE: 1390.3325, MAE: 201.0798, R²: 0.0015, MAPE: 91.12%, WMAPE: 102.26%\n",
            "Test  - RMSE: 861.0557, MAE: 107.3290, R²: 0.0124, MAPE: 93.00%, WMAPE: 117.28%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 390/500\n",
            "Train - RMSE: 1264.0642, MAE: 210.0598, R²: 0.0040, MAPE: 89.04%, WMAPE: 101.73%\n",
            "Val   - RMSE: 1389.9780, MAE: 201.1537, R²: 0.0020, MAPE: 91.08%, WMAPE: 102.30%\n",
            "Test  - RMSE: 860.8313, MAE: 107.6484, R²: 0.0129, MAPE: 93.00%, WMAPE: 117.63%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 400/500\n",
            "Train - RMSE: 1263.6121, MAE: 210.1049, R²: 0.0047, MAPE: 88.94%, WMAPE: 101.76%\n",
            "Val   - RMSE: 1389.6243, MAE: 201.2262, R²: 0.0025, MAPE: 91.04%, WMAPE: 102.34%\n",
            "Test  - RMSE: 860.6082, MAE: 107.9656, R²: 0.0135, MAPE: 93.00%, WMAPE: 117.98%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 410/500\n",
            "Train - RMSE: 1263.1621, MAE: 210.1496, R²: 0.0054, MAPE: 88.84%, WMAPE: 101.78%\n",
            "Val   - RMSE: 1389.2728, MAE: 201.2993, R²: 0.0030, MAPE: 91.00%, WMAPE: 102.37%\n",
            "Test  - RMSE: 860.3876, MAE: 108.2812, R²: 0.0140, MAPE: 93.01%, WMAPE: 118.32%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 420/500\n",
            "Train - RMSE: 1262.7136, MAE: 210.1925, R²: 0.0061, MAPE: 88.75%, WMAPE: 101.80%\n",
            "Val   - RMSE: 1388.9224, MAE: 201.3701, R²: 0.0035, MAPE: 90.96%, WMAPE: 102.41%\n",
            "Test  - RMSE: 860.1685, MAE: 108.5926, R²: 0.0145, MAPE: 93.01%, WMAPE: 118.66%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 430/500\n",
            "Train - RMSE: 1262.2661, MAE: 210.2344, R²: 0.0068, MAPE: 88.65%, WMAPE: 101.82%\n",
            "Val   - RMSE: 1388.5734, MAE: 201.4398, R²: 0.0040, MAPE: 90.90%, WMAPE: 102.44%\n",
            "Test  - RMSE: 859.9506, MAE: 108.9025, R²: 0.0150, MAPE: 93.00%, WMAPE: 119.00%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 440/500\n",
            "Train - RMSE: 1261.8208, MAE: 210.2758, R²: 0.0075, MAPE: 88.56%, WMAPE: 101.84%\n",
            "Val   - RMSE: 1388.2257, MAE: 201.5091, R²: 0.0045, MAPE: 90.86%, WMAPE: 102.48%\n",
            "Test  - RMSE: 859.7344, MAE: 109.2098, R²: 0.0155, MAPE: 93.00%, WMAPE: 119.34%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 450/500\n",
            "Train - RMSE: 1261.3767, MAE: 210.3161, R²: 0.0082, MAPE: 88.48%, WMAPE: 101.86%\n",
            "Val   - RMSE: 1387.8795, MAE: 201.5779, R²: 0.0050, MAPE: 90.82%, WMAPE: 102.51%\n",
            "Test  - RMSE: 859.5203, MAE: 109.5146, R²: 0.0159, MAPE: 93.01%, WMAPE: 119.67%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 460/500\n",
            "Train - RMSE: 1260.9338, MAE: 210.3554, R²: 0.0089, MAPE: 88.39%, WMAPE: 101.88%\n",
            "Val   - RMSE: 1387.5344, MAE: 201.6456, R²: 0.0055, MAPE: 90.79%, WMAPE: 102.55%\n",
            "Test  - RMSE: 859.3076, MAE: 109.8171, R²: 0.0164, MAPE: 93.01%, WMAPE: 120.00%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 470/500\n",
            "Train - RMSE: 1260.4924, MAE: 210.3932, R²: 0.0096, MAPE: 88.31%, WMAPE: 101.90%\n",
            "Val   - RMSE: 1387.1898, MAE: 201.7113, R²: 0.0060, MAPE: 90.74%, WMAPE: 102.58%\n",
            "Test  - RMSE: 859.0963, MAE: 110.1165, R²: 0.0169, MAPE: 93.01%, WMAPE: 120.33%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 480/500\n",
            "Train - RMSE: 1260.0509, MAE: 210.4302, R²: 0.0103, MAPE: 88.22%, WMAPE: 101.91%\n",
            "Val   - RMSE: 1386.8456, MAE: 201.7765, R²: 0.0065, MAPE: 90.70%, WMAPE: 102.62%\n",
            "Test  - RMSE: 858.8860, MAE: 110.4146, R²: 0.0174, MAPE: 93.01%, WMAPE: 120.65%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 490/500\n",
            "Train - RMSE: 1259.6124, MAE: 210.4677, R²: 0.0110, MAPE: 88.14%, WMAPE: 101.93%\n",
            "Val   - RMSE: 1386.5038, MAE: 201.8421, R²: 0.0070, MAPE: 90.66%, WMAPE: 102.65%\n",
            "Test  - RMSE: 858.6780, MAE: 110.7115, R²: 0.0179, MAPE: 93.01%, WMAPE: 120.98%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 500/500\n",
            "Train - RMSE: 1259.1718, MAE: 210.5027, R²: 0.0117, MAPE: 88.05%, WMAPE: 101.95%\n",
            "Val   - RMSE: 1386.1600, MAE: 201.9044, R²: 0.0075, MAPE: 90.62%, WMAPE: 102.68%\n",
            "Test  - RMSE: 858.4681, MAE: 111.0041, R²: 0.0184, MAPE: 93.00%, WMAPE: 121.30%\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate metrics for t=1 to t=5 and t=1 to t=13\n",
        "def calculate_final_metrics(y_true, y_pred, n_steps_list):\n",
        "    results = {}\n",
        "    for n in n_steps_list:\n",
        "        mse, rmse, mae, r2, mape_value, wmape_value = calculate_metrics(y_true, y_pred, n)\n",
        "        results[f'n={n}'] = {\n",
        "            'MSE': mse,\n",
        "            'RMSE': rmse,\n",
        "            'MAE': mae,\n",
        "            'R2': r2,\n",
        "            'MAPE': mape_value,\n",
        "            'WMAPE': wmape_value\n",
        "        }\n",
        "    return results\n",
        "\n",
        "# Evaluate on train set\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    y_pred_train = model(X_train)\n",
        "    train_results = calculate_final_metrics(y_train, y_pred_train, [5, 13])\n",
        "\n",
        "    y_pred_val = model(X_val)\n",
        "    val_results = calculate_final_metrics(y_val, y_pred_val, [5, 13])\n",
        "\n",
        "    y_pred_test = model(X_test)\n",
        "    test_results = calculate_final_metrics(y_test, y_pred_test, [5, 13])\n",
        "\n",
        "# Print final metrics\n",
        "def print_results(results, dataset_name):\n",
        "    print(f\"\\n{dataset_name} Metrics:\")\n",
        "    for n, metrics in results.items():\n",
        "        print(f\"\\nFrom t=1 to t={n.split('=')[1]}:\")\n",
        "        print(f\"MSE: {metrics['MSE']:.4f}\")\n",
        "        print(f\"RMSE: {metrics['RMSE']:.4f}\")\n",
        "        print(f\"MAE: {metrics['MAE']:.4f}\")\n",
        "        print(f\"R²: {metrics['R2']:.4f}\")\n",
        "        print(f\"MAPE: {metrics['MAPE']:.2f}%\")\n",
        "        print(f\"WMAPE: {metrics['WMAPE']:.2f}%\")\n",
        "\n",
        "print_results(train_results, \"Train\")\n",
        "print_results(val_results, \"Validation\")\n",
        "print_results(test_results, \"Test\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_VHQ0S_sFK8",
        "outputId": "ae7d5419-b045-4b0e-93bf-5ab3d676c61d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train Metrics:\n",
            "\n",
            "From t=1 to t=5:\n",
            "MSE: 1582615.5000\n",
            "RMSE: 1258.0205\n",
            "MAE: 210.3822\n",
            "R²: 0.0118\n",
            "MAPE: 88.37%\n",
            "WMAPE: 101.96%\n",
            "\n",
            "From t=1 to t=13:\n",
            "MSE: 1585513.5000\n",
            "RMSE: 1259.1718\n",
            "MAE: 210.5027\n",
            "R²: 0.0117\n",
            "MAPE: 88.05%\n",
            "WMAPE: 101.95%\n",
            "\n",
            "Validation Metrics:\n",
            "\n",
            "From t=1 to t=5:\n",
            "MSE: 1867773.6250\n",
            "RMSE: 1366.6652\n",
            "MAE: 203.1753\n",
            "R²: 0.0078\n",
            "MAPE: 90.41%\n",
            "WMAPE: 102.46%\n",
            "\n",
            "From t=1 to t=13:\n",
            "MSE: 1921439.5000\n",
            "RMSE: 1386.1600\n",
            "MAE: 201.9044\n",
            "R²: 0.0075\n",
            "MAPE: 90.62%\n",
            "WMAPE: 102.68%\n",
            "\n",
            "Test Metrics:\n",
            "\n",
            "From t=1 to t=5:\n",
            "MSE: 794872.4375\n",
            "RMSE: 891.5562\n",
            "MAE: 109.8009\n",
            "R²: 0.0165\n",
            "MAPE: 91.24%\n",
            "WMAPE: 121.65%\n",
            "\n",
            "From t=1 to t=13:\n",
            "MSE: 736967.4375\n",
            "RMSE: 858.4681\n",
            "MAE: 111.0041\n",
            "R²: 0.0184\n",
            "MAPE: 93.00%\n",
            "WMAPE: 121.30%\n"
          ]
        }
      ]
    }
  ]
}