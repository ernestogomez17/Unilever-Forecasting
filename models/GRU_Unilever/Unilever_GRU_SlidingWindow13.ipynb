{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NXFPl8Hm1CCJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from torch.utils.data import DataLoader, TensorDataset, Subset\n",
        "import sklearn.metrics as sk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dd4W9U3B1KA3",
        "outputId": "f4671ca3-1e62-4e82-ec13-e0ae372172f5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.load(\"/content/drive/MyDrive/Unilever Datasets, Sliding Window 13/HEALTHY SNACKING_dataset_processed (1).npz\")"
      ],
      "metadata": {
        "id": "8jUF4Rcz1ZBG"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Extract the arrays\n",
        "X = data['X']  # Shape: (timesteps, input_sequence_length, nodes, features)\n",
        "Y = data['Y']  # Shape: (timesteps, output_sequence_length, nodes, features)\n",
        "\n",
        "# Drop all features except the first one for both X and Y\n",
        "X = X[:, :, :, 0]  # Keep only the first feature\n",
        "Y = Y[:, :, :, 0]  # Keep only the first feature"
      ],
      "metadata": {
        "id": "8iTDCdggYumA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape Y to match the output format, if necessary\n",
        "# Y is expected to have shape (timestep/index, prediction window, nodes, 1)\n",
        "# If Y's shape is already correct, skip this step\n",
        "X = X.squeeze(-1)\n",
        "Y = Y.squeeze(-1)  # Remove the last dimension"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "ISX5rEk5YzE3",
        "outputId": "ff25d9c2-29ed-4961-bd74-20165118f2f1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "cannot select an axis to squeeze out which has size not equal to one",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-68f75499613f>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Y is expected to have shape (timestep/index, prediction window, nodes, 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# If Y's shape is already correct, skip this step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Remove the last dimension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: cannot select an axis to squeeze out which has size not equal to one"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Verify that the input and output sequence lengths are 13\n",
        "assert X.shape[1] == 13, f\"Expected input sequence length of 13, got {X.shape[1]}\"\n",
        "assert Y.shape[1] == 13, f\"Expected output sequence length of 13, got {Y.shape[1]}\"\n",
        "\n",
        "# Split the data into train, validation, and test sets (70%, 15%, 15%)\n",
        "train_size = int(len(X) * 0.7)\n",
        "val_size = int(len(X) * 0.15)\n",
        "test_size = len(X) - train_size - val_size\n",
        "\n",
        "X_train, X_val, X_test = X[:train_size], X[train_size:train_size + val_size], X[train_size + val_size:]\n",
        "y_train, y_val, y_test = Y[:train_size], Y[train_size:train_size + val_size], Y[train_size + val_size:]\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
        "X_val = torch.tensor(X_val, dtype=torch.float32)\n",
        "y_val = torch.tensor(y_val, dtype=torch.float32)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test = torch.tensor(y_test, dtype=torch.float32)\n",
        "\n",
        "# Print shapes to verify\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"X_val shape:\", X_val.shape)\n",
        "print(\"y_val shape:\", y_val.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_test shape:\", y_test.shape)\n",
        "\n"
      ],
      "metadata": {
        "id": "O2UBZn-X1tkU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "439be3bc-c72e-46c3-8181-7c461ab5cb51"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: torch.Size([116, 13, 1082])\n",
            "y_train shape: torch.Size([116, 13, 1082])\n",
            "X_val shape: torch.Size([25, 13, 1082])\n",
            "y_val shape: torch.Size([25, 13, 1082])\n",
            "X_test shape: torch.Size([26, 13, 1082])\n",
            "y_test shape: torch.Size([26, 13, 1082])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the GRU model\n",
        "class AirModel(nn.Module):\n",
        "    def __init__(self, input_sz, hidden_sz, output_sz, n_steps, dropout_prob=0.1):\n",
        "        super().__init__()\n",
        "        self.gru = nn.GRU(\n",
        "            input_size=input_sz,\n",
        "            hidden_size=hidden_sz,\n",
        "            num_layers=2,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.dropout = nn.Dropout(p=dropout_prob)\n",
        "        self.linear = nn.Linear(hidden_sz, output_sz * n_steps)\n",
        "        self.output_sz = output_sz\n",
        "        self.n_steps = n_steps\n",
        "\n",
        "    def forward(self, x):\n",
        "        x, _ = self.gru(x)\n",
        "        x = self.dropout(x[:, -1, :])  # Use the output from the last time step\n",
        "        x = self.linear(x)\n",
        "        x = torch.relu(x)\n",
        "        x = x.view(-1, self.n_steps, self.output_sz)  # Reshape to match the output format\n",
        "        return x\n",
        "\n",
        "# Model parameters\n",
        "input_size = X_train.shape[2]\n",
        "output_size = y_train.shape[2]\n",
        "model = AirModel(\n",
        "    input_sz=input_size,\n",
        "    hidden_sz=50,\n",
        "    output_sz=output_size,\n",
        "    n_steps=13,  # Updated to match the forecasting window\n",
        "    dropout_prob=0.1  # Added dropout for regularization\n",
        ")\n",
        "\n",
        "# Optimizer and loss function\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Reduced learning rate for stability\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "# Prepare the data loader\n",
        "train_data = TensorDataset(X_train, y_train)\n",
        "train_loader = DataLoader(train_data, batch_size=16, shuffle=False)\n",
        "\n",
        "# Lists to store metrics\n",
        "train_metrics = {'RMSE': [], 'MAE': [], 'R2': [], 'MSE': [], 'MAPE': [], 'WMAPE': []}\n",
        "val_metrics = {'RMSE': [], 'MAE': [], 'R2': [], 'MSE': [], 'MAPE': [], 'WMAPE': []}\n",
        "test_metrics = {'RMSE': [], 'MAE': [], 'R2': [], 'MSE': [], 'MAPE': [], 'WMAPE': []}\n",
        "\n",
        "# Function to calculate WMAPE\n",
        "def wmape(y_true, y_pred):\n",
        "    y_true = y_true.flatten()\n",
        "    y_pred = y_pred.flatten()\n",
        "    return np.sum(np.abs(y_true - y_pred)) / np.sum(np.abs(y_true))\n",
        "\n",
        "\n",
        "# Function to calculate MAPE\n",
        "def mape(y_true, y_pred):\n",
        "    y_true = y_true.flatten()\n",
        "    y_pred = y_pred.flatten()\n",
        "    # Create a mask for non-zero actuals\n",
        "    mask = y_true != 0\n",
        "    # Ensure there are non-zero actuals to prevent division by zero in the mean\n",
        "    if np.sum(mask) == 0:\n",
        "        return np.nan  # Or handle appropriately\n",
        "    # Compute MAPE only on non-zero actuals\n",
        "    return np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100\n",
        "\n",
        "\n",
        "# Training loop\n",
        "n_epochs = 500  # Reduced epochs for faster training during testing\n",
        "for epoch in range(n_epochs):\n",
        "    model.train()\n",
        "    for X_batch, y_batch in train_loader:\n",
        "        y_pred = model(X_batch)\n",
        "        loss = loss_fn(y_pred, y_batch)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    # Validation every epoch\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # Helper function to calculate metrics\n",
        "        def calculate_metrics(y_true, y_pred, n):\n",
        "            y_true = y_true[:, :n, :].cpu().numpy()\n",
        "            y_pred = y_pred[:, :n, :].cpu().numpy()\n",
        "\n",
        "            mse = mean_squared_error(y_true.flatten(), y_pred.flatten())\n",
        "            rmse = np.sqrt(mse)\n",
        "            mae = mean_absolute_error(y_true.flatten(), y_pred.flatten())\n",
        "            r2 = r2_score(y_true.flatten(), y_pred.flatten())\n",
        "            mape_value = mape(y_true, y_pred)\n",
        "            wmape_value = wmape(y_true, y_pred) * 100  # Expressed as percentage\n",
        "            return mse, rmse, mae, r2, mape_value, wmape_value\n",
        "\n",
        "        # Training metrics\n",
        "        y_pred_train = model(X_train)\n",
        "        mse_train, rmse_train, mae_train, r2_train, mape_train, wmape_train = calculate_metrics(y_train, y_pred_train, 13)\n",
        "        train_metrics['MSE'].append(mse_train)\n",
        "        train_metrics['RMSE'].append(rmse_train)\n",
        "        train_metrics['MAE'].append(mae_train)\n",
        "        train_metrics['R2'].append(r2_train)\n",
        "        train_metrics['MAPE'].append(mape_train)\n",
        "        train_metrics['WMAPE'].append(wmape_train)\n",
        "\n",
        "        # Validation metrics\n",
        "        y_pred_val = model(X_val)\n",
        "        mse_val, rmse_val, mae_val, r2_val, mape_val, wmape_val = calculate_metrics(y_val, y_pred_val, 13)\n",
        "        val_metrics['MSE'].append(mse_val)\n",
        "        val_metrics['RMSE'].append(rmse_val)\n",
        "        val_metrics['MAE'].append(mae_val)\n",
        "        val_metrics['R2'].append(r2_val)\n",
        "        val_metrics['MAPE'].append(mape_val)\n",
        "        val_metrics['WMAPE'].append(wmape_val)\n",
        "\n",
        "        # Testing metrics\n",
        "        y_pred_test = model(X_test)\n",
        "        mse_test, rmse_test, mae_test, r2_test, mape_test, wmape_test = calculate_metrics(y_test, y_pred_test, 13)\n",
        "        test_metrics['MSE'].append(mse_test)\n",
        "        test_metrics['RMSE'].append(rmse_test)\n",
        "        test_metrics['MAE'].append(mae_test)\n",
        "        test_metrics['R2'].append(r2_test)\n",
        "        test_metrics['MAPE'].append(mape_test)\n",
        "        test_metrics['WMAPE'].append(wmape_test)\n",
        "\n",
        "    # Print metrics every 10 epochs\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f\"Epoch {epoch+1}/{n_epochs}\")\n",
        "        print(f\"Train - RMSE: {rmse_train:.4f}, MAE: {mae_train:.4f}, R²: {r2_train:.4f}, MAPE: {mape_train:.2f}%, WMAPE: {wmape_train:.2f}%\")\n",
        "        print(f\"Val   - RMSE: {rmse_val:.4f}, MAE: {mae_val:.4f}, R²: {r2_val:.4f}, MAPE: {mape_val:.2f}%, WMAPE: {wmape_val:.2f}%\")\n",
        "        print(f\"Test  - RMSE: {rmse_test:.4f}, MAE: {mae_test:.4f}, R²: {r2_test:.4f}, MAPE: {mape_test:.2f}%, WMAPE: {wmape_test:.2f}%\")\n",
        "        print(\"-\" * 80)"
      ],
      "metadata": {
        "id": "YS5ZGkF02TYW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a819a52b-042f-4305-9c74-d6a0e11a32c5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/500\n",
            "Train - RMSE: 1282.7100, MAE: 206.7632, R²: -0.0256, MAPE: 96.76%, WMAPE: 100.14%\n",
            "Val   - RMSE: 1404.7397, MAE: 196.9567, R²: -0.0193, MAPE: 97.62%, WMAPE: 100.16%\n",
            "Test  - RMSE: 870.9279, MAE: 92.2407, R²: -0.0103, MAPE: 97.89%, WMAPE: 100.80%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 20/500\n",
            "Train - RMSE: 1282.0996, MAE: 207.0038, R²: -0.0247, MAPE: 95.72%, WMAPE: 100.25%\n",
            "Val   - RMSE: 1404.2490, MAE: 197.2177, R²: -0.0186, MAPE: 96.43%, WMAPE: 100.30%\n",
            "Test  - RMSE: 870.5641, MAE: 92.9298, R²: -0.0095, MAPE: 96.61%, WMAPE: 101.55%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 30/500\n",
            "Train - RMSE: 1281.5258, MAE: 207.2101, R²: -0.0238, MAPE: 95.11%, WMAPE: 100.35%\n",
            "Val   - RMSE: 1403.7872, MAE: 197.4409, R²: -0.0179, MAPE: 95.65%, WMAPE: 100.41%\n",
            "Test  - RMSE: 870.2241, MAE: 93.5490, R²: -0.0087, MAPE: 95.76%, WMAPE: 102.23%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 40/500\n",
            "Train - RMSE: 1280.9645, MAE: 207.3999, R²: -0.0229, MAPE: 94.75%, WMAPE: 100.45%\n",
            "Val   - RMSE: 1403.3352, MAE: 197.6465, R²: -0.0173, MAPE: 95.10%, WMAPE: 100.52%\n",
            "Test  - RMSE: 869.8940, MAE: 94.1361, R²: -0.0079, MAPE: 95.17%, WMAPE: 102.87%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 50/500\n",
            "Train - RMSE: 1280.4120, MAE: 207.5748, R²: -0.0220, MAPE: 94.49%, WMAPE: 100.53%\n",
            "Val   - RMSE: 1402.8901, MAE: 197.8369, R²: -0.0166, MAPE: 94.67%, WMAPE: 100.61%\n",
            "Test  - RMSE: 869.5709, MAE: 94.6977, R²: -0.0072, MAPE: 94.80%, WMAPE: 103.48%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 60/500\n",
            "Train - RMSE: 1279.8677, MAE: 207.7388, R²: -0.0211, MAPE: 94.27%, WMAPE: 100.61%\n",
            "Val   - RMSE: 1402.4523, MAE: 198.0180, R²: -0.0160, MAPE: 94.32%, WMAPE: 100.70%\n",
            "Test  - RMSE: 869.2546, MAE: 95.2411, R²: -0.0065, MAPE: 94.54%, WMAPE: 104.07%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 70/500\n",
            "Train - RMSE: 1279.3251, MAE: 207.8919, R²: -0.0202, MAPE: 94.10%, WMAPE: 100.68%\n",
            "Val   - RMSE: 1402.0159, MAE: 198.1894, R²: -0.0153, MAPE: 94.06%, WMAPE: 100.79%\n",
            "Test  - RMSE: 868.9421, MAE: 95.7667, R²: -0.0057, MAPE: 94.31%, WMAPE: 104.65%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 80/500\n",
            "Train - RMSE: 1278.7893, MAE: 208.0355, R²: -0.0194, MAPE: 93.93%, WMAPE: 100.75%\n",
            "Val   - RMSE: 1401.5856, MAE: 198.3516, R²: -0.0147, MAPE: 93.83%, WMAPE: 100.87%\n",
            "Test  - RMSE: 868.6346, MAE: 96.2768, R²: -0.0050, MAPE: 94.14%, WMAPE: 105.21%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 90/500\n",
            "Train - RMSE: 1278.2574, MAE: 208.1720, R²: -0.0185, MAPE: 93.75%, WMAPE: 100.82%\n",
            "Val   - RMSE: 1401.1595, MAE: 198.5074, R²: -0.0141, MAPE: 93.62%, WMAPE: 100.95%\n",
            "Test  - RMSE: 868.3312, MAE: 96.7750, R²: -0.0043, MAPE: 93.99%, WMAPE: 105.75%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 100/500\n",
            "Train - RMSE: 1277.7267, MAE: 208.3019, R²: -0.0177, MAPE: 93.57%, WMAPE: 100.88%\n",
            "Val   - RMSE: 1400.7349, MAE: 198.6570, R²: -0.0135, MAPE: 93.43%, WMAPE: 101.03%\n",
            "Test  - RMSE: 868.0305, MAE: 97.2627, R²: -0.0036, MAPE: 93.88%, WMAPE: 106.28%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 110/500\n",
            "Train - RMSE: 1277.2010, MAE: 208.4254, R²: -0.0169, MAPE: 93.39%, WMAPE: 100.94%\n",
            "Val   - RMSE: 1400.3146, MAE: 198.8012, R²: -0.0129, MAPE: 93.26%, WMAPE: 101.10%\n",
            "Test  - RMSE: 867.7338, MAE: 97.7395, R²: -0.0029, MAPE: 93.79%, WMAPE: 106.80%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 120/500\n",
            "Train - RMSE: 1276.6771, MAE: 208.5427, R²: -0.0160, MAPE: 93.21%, WMAPE: 101.00%\n",
            "Val   - RMSE: 1399.8959, MAE: 198.9396, R²: -0.0123, MAPE: 93.10%, WMAPE: 101.17%\n",
            "Test  - RMSE: 867.4397, MAE: 98.2071, R²: -0.0023, MAPE: 93.72%, WMAPE: 107.32%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 130/500\n",
            "Train - RMSE: 1276.1570, MAE: 208.6536, R²: -0.0152, MAPE: 93.01%, WMAPE: 101.05%\n",
            "Val   - RMSE: 1399.4796, MAE: 199.0720, R²: -0.0117, MAPE: 92.94%, WMAPE: 101.24%\n",
            "Test  - RMSE: 867.1487, MAE: 98.6646, R²: -0.0016, MAPE: 93.64%, WMAPE: 107.82%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 140/500\n",
            "Train - RMSE: 1275.6389, MAE: 208.7602, R²: -0.0144, MAPE: 92.81%, WMAPE: 101.10%\n",
            "Val   - RMSE: 1399.0663, MAE: 199.2006, R²: -0.0111, MAPE: 92.80%, WMAPE: 101.31%\n",
            "Test  - RMSE: 866.8604, MAE: 99.1139, R²: -0.0009, MAPE: 93.57%, WMAPE: 108.31%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 150/500\n",
            "Train - RMSE: 1275.1211, MAE: 208.8626, R²: -0.0135, MAPE: 92.60%, WMAPE: 101.15%\n",
            "Val   - RMSE: 1398.6532, MAE: 199.3253, R²: -0.0105, MAPE: 92.63%, WMAPE: 101.37%\n",
            "Test  - RMSE: 866.5723, MAE: 99.5570, R²: -0.0003, MAPE: 93.49%, WMAPE: 108.79%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 160/500\n",
            "Train - RMSE: 1274.6071, MAE: 208.9601, R²: -0.0127, MAPE: 92.39%, WMAPE: 101.20%\n",
            "Val   - RMSE: 1398.2422, MAE: 199.4438, R²: -0.0099, MAPE: 92.47%, WMAPE: 101.43%\n",
            "Test  - RMSE: 866.2875, MAE: 99.9917, R²: 0.0004, MAPE: 93.43%, WMAPE: 109.27%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 170/500\n",
            "Train - RMSE: 1274.0945, MAE: 209.0528, R²: -0.0119, MAPE: 92.17%, WMAPE: 101.25%\n",
            "Val   - RMSE: 1397.8337, MAE: 199.5577, R²: -0.0093, MAPE: 92.31%, WMAPE: 101.49%\n",
            "Test  - RMSE: 866.0056, MAE: 100.4193, R²: 0.0010, MAPE: 93.36%, WMAPE: 109.73%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 180/500\n",
            "Train - RMSE: 1273.5847, MAE: 209.1427, R²: -0.0111, MAPE: 91.96%, WMAPE: 101.29%\n",
            "Val   - RMSE: 1397.4271, MAE: 199.6697, R²: -0.0087, MAPE: 92.16%, WMAPE: 101.54%\n",
            "Test  - RMSE: 865.7269, MAE: 100.8418, R²: 0.0017, MAPE: 93.30%, WMAPE: 110.19%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 190/500\n",
            "Train - RMSE: 1273.0782, MAE: 209.2292, R²: -0.0103, MAPE: 91.74%, WMAPE: 101.33%\n",
            "Val   - RMSE: 1397.0237, MAE: 199.7790, R²: -0.0081, MAPE: 92.01%, WMAPE: 101.60%\n",
            "Test  - RMSE: 865.4512, MAE: 101.2577, R²: 0.0023, MAPE: 93.23%, WMAPE: 110.65%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 200/500\n",
            "Train - RMSE: 1272.5747, MAE: 209.3118, R²: -0.0095, MAPE: 91.53%, WMAPE: 101.37%\n",
            "Val   - RMSE: 1396.6237, MAE: 199.8849, R²: -0.0076, MAPE: 91.86%, WMAPE: 101.65%\n",
            "Test  - RMSE: 865.1788, MAE: 101.6666, R²: 0.0029, MAPE: 93.17%, WMAPE: 111.10%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 210/500\n",
            "Train - RMSE: 1272.0726, MAE: 209.3907, R²: -0.0087, MAPE: 91.30%, WMAPE: 101.41%\n",
            "Val   - RMSE: 1396.2246, MAE: 199.9873, R²: -0.0070, MAPE: 91.70%, WMAPE: 101.71%\n",
            "Test  - RMSE: 864.9085, MAE: 102.0700, R²: 0.0036, MAPE: 93.09%, WMAPE: 111.54%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 220/500\n",
            "Train - RMSE: 1271.5734, MAE: 209.4663, R²: -0.0079, MAPE: 91.09%, WMAPE: 101.45%\n",
            "Val   - RMSE: 1395.8279, MAE: 200.0869, R²: -0.0064, MAPE: 91.56%, WMAPE: 101.76%\n",
            "Test  - RMSE: 864.6408, MAE: 102.4675, R²: 0.0042, MAPE: 93.03%, WMAPE: 111.97%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 230/500\n",
            "Train - RMSE: 1271.0770, MAE: 209.5402, R²: -0.0071, MAPE: 90.88%, WMAPE: 101.48%\n",
            "Val   - RMSE: 1395.4338, MAE: 200.1838, R²: -0.0058, MAPE: 91.40%, WMAPE: 101.81%\n",
            "Test  - RMSE: 864.3759, MAE: 102.8604, R²: 0.0048, MAPE: 92.96%, WMAPE: 112.40%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 240/500\n",
            "Train - RMSE: 1270.5825, MAE: 209.6118, R²: -0.0063, MAPE: 90.69%, WMAPE: 101.52%\n",
            "Val   - RMSE: 1395.0416, MAE: 200.2791, R²: -0.0053, MAPE: 91.27%, WMAPE: 101.85%\n",
            "Test  - RMSE: 864.1132, MAE: 103.2486, R²: 0.0054, MAPE: 92.91%, WMAPE: 112.82%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 250/500\n",
            "Train - RMSE: 1270.0890, MAE: 209.6815, R²: -0.0056, MAPE: 90.49%, WMAPE: 101.55%\n",
            "Val   - RMSE: 1394.6505, MAE: 200.3730, R²: -0.0047, MAPE: 91.13%, WMAPE: 101.90%\n",
            "Test  - RMSE: 863.8525, MAE: 103.6332, R²: 0.0060, MAPE: 92.86%, WMAPE: 113.24%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 260/500\n",
            "Train - RMSE: 1269.5964, MAE: 209.7490, R²: -0.0048, MAPE: 90.30%, WMAPE: 101.58%\n",
            "Val   - RMSE: 1394.2600, MAE: 200.4648, R²: -0.0041, MAPE: 91.01%, WMAPE: 101.95%\n",
            "Test  - RMSE: 863.5934, MAE: 104.0131, R²: 0.0066, MAPE: 92.81%, WMAPE: 113.66%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 270/500\n",
            "Train - RMSE: 1269.1077, MAE: 209.8158, R²: -0.0040, MAPE: 90.11%, WMAPE: 101.62%\n",
            "Val   - RMSE: 1393.8729, MAE: 200.5564, R²: -0.0036, MAPE: 90.88%, WMAPE: 102.00%\n",
            "Test  - RMSE: 863.3372, MAE: 104.3895, R²: 0.0072, MAPE: 92.77%, WMAPE: 114.07%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 280/500\n",
            "Train - RMSE: 1268.6201, MAE: 209.8805, R²: -0.0032, MAPE: 89.93%, WMAPE: 101.65%\n",
            "Val   - RMSE: 1393.4866, MAE: 200.6454, R²: -0.0030, MAPE: 90.77%, WMAPE: 102.04%\n",
            "Test  - RMSE: 863.0825, MAE: 104.7609, R²: 0.0078, MAPE: 92.73%, WMAPE: 114.48%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 290/500\n",
            "Train - RMSE: 1268.1349, MAE: 209.9440, R²: -0.0025, MAPE: 89.76%, WMAPE: 101.68%\n",
            "Val   - RMSE: 1393.1023, MAE: 200.7337, R²: -0.0025, MAPE: 90.66%, WMAPE: 102.09%\n",
            "Test  - RMSE: 862.8298, MAE: 105.1290, R²: 0.0084, MAPE: 92.69%, WMAPE: 114.88%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 300/500\n",
            "Train - RMSE: 1267.6517, MAE: 210.0064, R²: -0.0017, MAPE: 89.59%, WMAPE: 101.71%\n",
            "Val   - RMSE: 1392.7195, MAE: 200.8214, R²: -0.0019, MAPE: 90.57%, WMAPE: 102.13%\n",
            "Test  - RMSE: 862.5792, MAE: 105.4935, R²: 0.0089, MAPE: 92.67%, WMAPE: 115.28%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 310/500\n",
            "Train - RMSE: 1267.1687, MAE: 210.0683, R²: -0.0009, MAPE: 89.43%, WMAPE: 101.74%\n",
            "Val   - RMSE: 1392.3380, MAE: 200.9101, R²: -0.0014, MAPE: 90.47%, WMAPE: 102.18%\n",
            "Test  - RMSE: 862.3302, MAE: 105.8559, R²: 0.0095, MAPE: 92.64%, WMAPE: 115.67%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 320/500\n",
            "Train - RMSE: 1266.6902, MAE: 210.1308, R²: -0.0002, MAPE: 89.29%, WMAPE: 101.77%\n",
            "Val   - RMSE: 1391.9600, MAE: 201.0000, R²: -0.0008, MAPE: 90.40%, WMAPE: 102.22%\n",
            "Test  - RMSE: 862.0850, MAE: 106.2159, R²: 0.0101, MAPE: 92.63%, WMAPE: 116.07%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 330/500\n",
            "Train - RMSE: 1266.2124, MAE: 210.1911, R²: 0.0006, MAPE: 89.15%, WMAPE: 101.80%\n",
            "Val   - RMSE: 1391.5825, MAE: 201.0867, R²: -0.0003, MAPE: 90.32%, WMAPE: 102.26%\n",
            "Test  - RMSE: 861.8409, MAE: 106.5711, R²: 0.0106, MAPE: 92.61%, WMAPE: 116.45%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 340/500\n",
            "Train - RMSE: 1265.7360, MAE: 210.2499, R²: 0.0013, MAPE: 89.02%, WMAPE: 101.83%\n",
            "Val   - RMSE: 1391.2064, MAE: 201.1719, R²: 0.0002, MAPE: 90.25%, WMAPE: 102.31%\n",
            "Test  - RMSE: 861.5988, MAE: 106.9226, R²: 0.0112, MAPE: 92.60%, WMAPE: 116.84%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 350/500\n",
            "Train - RMSE: 1265.2603, MAE: 210.3076, R²: 0.0021, MAPE: 88.89%, WMAPE: 101.85%\n",
            "Val   - RMSE: 1390.8313, MAE: 201.2563, R²: 0.0008, MAPE: 90.19%, WMAPE: 102.35%\n",
            "Test  - RMSE: 861.3578, MAE: 107.2713, R²: 0.0117, MAPE: 92.58%, WMAPE: 117.22%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 360/500\n",
            "Train - RMSE: 1264.7854, MAE: 210.3646, R²: 0.0028, MAPE: 88.76%, WMAPE: 101.88%\n",
            "Val   - RMSE: 1390.4569, MAE: 201.3399, R²: 0.0013, MAPE: 90.12%, WMAPE: 102.39%\n",
            "Test  - RMSE: 861.1188, MAE: 107.6173, R²: 0.0123, MAPE: 92.57%, WMAPE: 117.60%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 370/500\n",
            "Train - RMSE: 1264.3141, MAE: 210.4212, R²: 0.0036, MAPE: 88.65%, WMAPE: 101.91%\n",
            "Val   - RMSE: 1390.0856, MAE: 201.4241, R²: 0.0019, MAPE: 90.07%, WMAPE: 102.44%\n",
            "Test  - RMSE: 860.8824, MAE: 107.9612, R²: 0.0128, MAPE: 92.57%, WMAPE: 117.97%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 380/500\n",
            "Train - RMSE: 1263.8431, MAE: 210.4756, R²: 0.0043, MAPE: 88.54%, WMAPE: 101.94%\n",
            "Val   - RMSE: 1389.7144, MAE: 201.5049, R²: 0.0024, MAPE: 90.02%, WMAPE: 102.48%\n",
            "Test  - RMSE: 860.6472, MAE: 108.2999, R²: 0.0134, MAPE: 92.57%, WMAPE: 118.34%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 390/500\n",
            "Train - RMSE: 1263.3750, MAE: 210.5298, R²: 0.0050, MAPE: 88.43%, WMAPE: 101.96%\n",
            "Val   - RMSE: 1389.3456, MAE: 201.5862, R²: 0.0029, MAPE: 89.97%, WMAPE: 102.52%\n",
            "Test  - RMSE: 860.4143, MAE: 108.6370, R²: 0.0139, MAPE: 92.56%, WMAPE: 118.71%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 400/500\n",
            "Train - RMSE: 1262.9084, MAE: 210.5832, R²: 0.0058, MAPE: 88.33%, WMAPE: 101.99%\n",
            "Val   - RMSE: 1388.9791, MAE: 201.6677, R²: 0.0034, MAPE: 89.93%, WMAPE: 102.56%\n",
            "Test  - RMSE: 860.1839, MAE: 108.9723, R²: 0.0144, MAPE: 92.57%, WMAPE: 119.08%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 410/500\n",
            "Train - RMSE: 1262.4437, MAE: 210.6346, R²: 0.0065, MAPE: 88.24%, WMAPE: 102.01%\n",
            "Val   - RMSE: 1388.6134, MAE: 201.7470, R²: 0.0040, MAPE: 89.88%, WMAPE: 102.60%\n",
            "Test  - RMSE: 859.9548, MAE: 109.3038, R²: 0.0150, MAPE: 92.57%, WMAPE: 119.44%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 420/500\n",
            "Train - RMSE: 1261.9802, MAE: 210.6847, R²: 0.0072, MAPE: 88.13%, WMAPE: 102.04%\n",
            "Val   - RMSE: 1388.2493, MAE: 201.8259, R²: 0.0045, MAPE: 89.84%, WMAPE: 102.64%\n",
            "Test  - RMSE: 859.7275, MAE: 109.6337, R²: 0.0155, MAPE: 92.57%, WMAPE: 119.80%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 430/500\n",
            "Train - RMSE: 1261.5173, MAE: 210.7345, R²: 0.0080, MAPE: 88.04%, WMAPE: 102.06%\n",
            "Val   - RMSE: 1387.8857, MAE: 201.9047, R²: 0.0050, MAPE: 89.79%, WMAPE: 102.68%\n",
            "Test  - RMSE: 859.5023, MAE: 109.9622, R²: 0.0160, MAPE: 92.57%, WMAPE: 120.16%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 440/500\n",
            "Train - RMSE: 1261.0566, MAE: 210.7830, R²: 0.0087, MAPE: 87.95%, WMAPE: 102.08%\n",
            "Val   - RMSE: 1387.5238, MAE: 201.9820, R²: 0.0055, MAPE: 89.75%, WMAPE: 102.72%\n",
            "Test  - RMSE: 859.2786, MAE: 110.2874, R²: 0.0165, MAPE: 92.58%, WMAPE: 120.52%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 450/500\n",
            "Train - RMSE: 1260.5963, MAE: 210.8297, R²: 0.0094, MAPE: 87.86%, WMAPE: 102.11%\n",
            "Val   - RMSE: 1387.1632, MAE: 202.0574, R²: 0.0060, MAPE: 89.71%, WMAPE: 102.76%\n",
            "Test  - RMSE: 859.0563, MAE: 110.6091, R²: 0.0170, MAPE: 92.58%, WMAPE: 120.87%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 460/500\n",
            "Train - RMSE: 1260.1384, MAE: 210.8762, R²: 0.0101, MAPE: 87.77%, WMAPE: 102.13%\n",
            "Val   - RMSE: 1386.8040, MAE: 202.1322, R²: 0.0066, MAPE: 89.66%, WMAPE: 102.80%\n",
            "Test  - RMSE: 858.8358, MAE: 110.9287, R²: 0.0175, MAPE: 92.57%, WMAPE: 121.22%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 470/500\n",
            "Train - RMSE: 1259.6821, MAE: 210.9207, R²: 0.0108, MAPE: 87.68%, WMAPE: 102.15%\n",
            "Val   - RMSE: 1386.4458, MAE: 202.2052, R²: 0.0071, MAPE: 89.62%, WMAPE: 102.83%\n",
            "Test  - RMSE: 858.6169, MAE: 111.2451, R²: 0.0180, MAPE: 92.58%, WMAPE: 121.56%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 480/500\n",
            "Train - RMSE: 1259.2262, MAE: 210.9642, R²: 0.0116, MAPE: 87.59%, WMAPE: 102.17%\n",
            "Val   - RMSE: 1386.0889, MAE: 202.2769, R²: 0.0076, MAPE: 89.57%, WMAPE: 102.87%\n",
            "Test  - RMSE: 858.3994, MAE: 111.5589, R²: 0.0185, MAPE: 92.57%, WMAPE: 121.91%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 490/500\n",
            "Train - RMSE: 1258.7726, MAE: 211.0071, R²: 0.0123, MAPE: 87.50%, WMAPE: 102.19%\n",
            "Val   - RMSE: 1385.7334, MAE: 202.3480, R²: 0.0081, MAPE: 89.53%, WMAPE: 102.91%\n",
            "Test  - RMSE: 858.1838, MAE: 111.8707, R²: 0.0190, MAPE: 92.57%, WMAPE: 122.25%\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 500/500\n",
            "Train - RMSE: 1258.3199, MAE: 211.0489, R²: 0.0130, MAPE: 87.42%, WMAPE: 102.21%\n",
            "Val   - RMSE: 1385.3794, MAE: 202.4178, R²: 0.0086, MAPE: 89.49%, WMAPE: 102.94%\n",
            "Test  - RMSE: 857.9698, MAE: 112.1796, R²: 0.0195, MAPE: 92.57%, WMAPE: 122.58%\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_true_flat = y_train.cpu().numpy().flatten()\n",
        "num_zeros = np.sum(y_true_flat == 0)\n",
        "print(f\"Number of zero values in y_true: {num_zeros}\")"
      ],
      "metadata": {
        "id": "YcBmaJhEfFzF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bb24a8a-fdf0-49ae-82b8-11adf1163de6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of zero values in y_true: 1413067\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_values = y_true_flat.size  # Assuming y_true_flat is a flattened version of y_true\n",
        "percentage_zeros = (num_zeros / total_values) * 100\n",
        "print(f\"Percentage of zero values in y_true: {percentage_zeros:.2f}%\")"
      ],
      "metadata": {
        "id": "BcnjhLiKfhHn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38a7c3e7-1940-4b94-b64a-3ccea7fe6dcc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Percentage of zero values in y_true: 86.60%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate metrics for t=1 to t=5 and t=1 to t=13\n",
        "def calculate_final_metrics(y_true, y_pred, n_steps_list):\n",
        "    results = {}\n",
        "    for n in n_steps_list:\n",
        "        mse, rmse, mae, r2, mape_value, wmape_value = calculate_metrics(y_true, y_pred, n)\n",
        "        results[f'n={n}'] = {\n",
        "            'MSE': mse,\n",
        "            'RMSE': rmse,\n",
        "            'MAE': mae,\n",
        "            'R2': r2,\n",
        "            'MAPE': mape_value,\n",
        "            'WMAPE': wmape_value\n",
        "        }\n",
        "    return results\n",
        "\n",
        "# Evaluate on train set\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    y_pred_train = model(X_train)\n",
        "    train_results = calculate_final_metrics(y_train, y_pred_train, [5, 13])\n",
        "\n",
        "    y_pred_val = model(X_val)\n",
        "    val_results = calculate_final_metrics(y_val, y_pred_val, [5, 13])\n",
        "\n",
        "    y_pred_test = model(X_test)\n",
        "    test_results = calculate_final_metrics(y_test, y_pred_test, [5, 13])\n",
        "\n",
        "# Print final metrics\n",
        "def print_results(results, dataset_name):\n",
        "    print(f\"\\n{dataset_name} Metrics:\")\n",
        "    for n, metrics in results.items():\n",
        "        print(f\"\\nFrom t=1 to t={n.split('=')[1]}:\")\n",
        "        print(f\"MSE: {metrics['MSE']:.4f}\")\n",
        "        print(f\"RMSE: {metrics['RMSE']:.4f}\")\n",
        "        print(f\"MAE: {metrics['MAE']:.4f}\")\n",
        "        print(f\"R²: {metrics['R2']:.4f}\")\n",
        "        print(f\"MAPE: {metrics['MAPE']:.2f}%\")\n",
        "        print(f\"WMAPE: {metrics['WMAPE']:.2f}%\")\n",
        "\n",
        "print_results(train_results, \"Train\")\n",
        "print_results(val_results, \"Validation\")\n",
        "print_results(test_results, \"Test\")"
      ],
      "metadata": {
        "id": "tRnE3pJo2h-4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5afe7c89-603f-4159-963d-2531174e2162"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train Metrics:\n",
            "\n",
            "From t=1 to t=5:\n",
            "MSE: 1581413.3750\n",
            "RMSE: 1257.5426\n",
            "MAE: 210.9650\n",
            "R²: 0.0126\n",
            "MAPE: 87.43%\n",
            "WMAPE: 102.24%\n",
            "\n",
            "From t=1 to t=13:\n",
            "MSE: 1583369.0000\n",
            "RMSE: 1258.3199\n",
            "MAE: 211.0489\n",
            "R²: 0.0130\n",
            "MAPE: 87.42%\n",
            "WMAPE: 102.21%\n",
            "\n",
            "Validation Metrics:\n",
            "\n",
            "From t=1 to t=5:\n",
            "MSE: 1866532.1250\n",
            "RMSE: 1366.2108\n",
            "MAE: 203.6246\n",
            "R²: 0.0085\n",
            "MAPE: 88.48%\n",
            "WMAPE: 102.68%\n",
            "\n",
            "From t=1 to t=13:\n",
            "MSE: 1919276.1250\n",
            "RMSE: 1385.3794\n",
            "MAE: 202.4178\n",
            "R²: 0.0086\n",
            "MAPE: 89.49%\n",
            "WMAPE: 102.94%\n",
            "\n",
            "Test Metrics:\n",
            "\n",
            "From t=1 to t=5:\n",
            "MSE: 794632.8750\n",
            "RMSE: 891.4218\n",
            "MAE: 110.9237\n",
            "R²: 0.0168\n",
            "MAPE: 90.45%\n",
            "WMAPE: 122.90%\n",
            "\n",
            "From t=1 to t=13:\n",
            "MSE: 736112.3125\n",
            "RMSE: 857.9698\n",
            "MAE: 112.1796\n",
            "R²: 0.0195\n",
            "MAPE: 92.57%\n",
            "WMAPE: 122.58%\n"
          ]
        }
      ]
    }
  ]
}